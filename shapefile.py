# streamlit_app.py
# pip install streamlit geopandas shapely folium streamlit-folium xlsxwriter rtree openpyxl

import re
import unicodedata
import zipfile
import tempfile
import html
from io import BytesIO
from typing import List, Optional, Tuple, Dict

import pandas as pd
import geopandas as gpd
import streamlit as st
import folium
from shapely.geometry.base import BaseGeometry
from shapely.wkt import loads as wkt_loads
from shapely.errors import WKTReadingError
from streamlit_folium import folium_static


# =========================
# Page / Session
# =========================
st.set_page_config(page_title="ç­†ãƒãƒªã‚´ãƒ³Ã—ãƒ”ãƒ³ çµåˆ â†’ ä½æ‰€ç…§åˆ â†’ å‡ºåŠ›", layout="wide")

ADDRESS_COL_CANONICAL = "Address"  # ç©ºé–“çµåˆçµæœå´ã¯ Address å›ºå®šã§ä½¿ç”¨
LABEL_FONT_SIZE = 16               # ãƒ©ãƒ™ãƒ«æ–‡å­—ã‚µã‚¤ã‚ºå›ºå®š

STATE_DEFAULTS = {
    "merged_pori": None,
    "merged_pins": None,
    "joined": None,
    "matched": None,
    "excel_hash": None,
    "sheet_name": None,
    "header_row": None,
    "excel_addr_col": None,
    "strip_last_num": True,
    "show_map": False,
    "uploader_nonce": 0,   # uploaderå¼·åˆ¶ãƒªã‚»ãƒƒãƒˆç”¨
    "upload_error": None,  # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ¶ç´„é•åãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
}
for k, v in STATE_DEFAULTS.items():
    st.session_state.setdefault(k, v)


# =========================
# UI Style
# =========================
CSS = """
<style>
:root{
  --muted: rgba(120,120,120,.9);
  --card: rgba(255,255,255,.04);
  --card2: rgba(255,255,255,.06);
  --border: rgba(255,255,255,.10);
}
.block-container{padding-top: 1.2rem;}
h1,h2,h3{letter-spacing: .2px;}
.hr{height:1px; background: var(--border); margin: 1.1rem 0;}
.step{
  padding: .7rem .9rem; border: 1px solid var(--border); border-radius: 14px;
  background: var(--card); margin-bottom: .8rem;
}
.step-title{font-size:1.05rem; font-weight:700; margin-bottom:.1rem;}
.step-desc{color:var(--muted); font-size:.92rem; margin-bottom:.6rem;}
.kpi{
  padding:.65rem .75rem; border:1px solid var(--border); border-radius: 14px;
  background: var(--card2);
}
.sidebar-title{font-weight:800; margin-bottom:.35rem;}
.sidebar-item{margin: .35rem 0;}
</style>
"""
st.markdown(CSS, unsafe_allow_html=True)


# =========================
# Reset + Strict upload restriction
# =========================
def reset_all():
    for k in list(STATE_DEFAULTS.keys()):
        st.session_state[k] = STATE_DEFAULTS[k]

def norm_filename(s: str) -> str:
    s = unicodedata.normalize("NFKC", s or "")
    s = s.replace("ã€€", " ")
    s = re.sub(r"\s+", "", s)
    return s

def fail_upload(msg: str):
    st.session_state.upload_error = msg
    st.session_state.uploader_nonce += 1  # keyã‚’å¤‰ãˆã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’å¼·åˆ¶ã‚¯ãƒªã‚¢
    st.rerun()

def validate_filename_or_reset(files, must_include_any: List[str], label: str):
    # Streamlitã®UIå´ã§ã€Œé¸æŠä¸å¯ã€ã«ã¯ã§ããªã„ãŸã‚ã€é¸æŠå¾Œã«å³æ ¼ãƒã‚§ãƒƒã‚¯â†’é•åãªã‚‰å³ã‚¯ãƒªã‚¢
    if not files:
        return
    musts = [norm_filename(x) for x in must_include_any]
    for f in files:
        name_norm = norm_filename(f.name)
        if not any(m in name_norm for m in musts):
            allow = " / ".join(must_include_any)
            fail_upload(f"âŒ {label} ã¯ãƒ•ã‚¡ã‚¤ãƒ«åã«ã€Œ{allow}ã€ã‚’å«ã‚€ GeoJSON ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")

def files_ok(files, allow_any: List[str]) -> bool:
    if not files:
        return True
    allow = [norm_filename(x) for x in allow_any]
    for f in files:
        n = norm_filename(f.name)
        if not any(a in n for a in allow):
            return False
    return True


# =========================
# Helpers: Preview (NO toolbar)
# =========================
def slim_gdf_preview(gdf: gpd.GeoDataFrame, n: int = 5, max_cols: int = 12) -> pd.DataFrame:
    """st.tableç”¨ï¼ˆãƒ„ãƒ¼ãƒ«ãƒãƒ¼ç„¡ã—ï¼‰"""
    if gdf is None or getattr(gdf, "empty", True):
        return pd.DataFrame()
    df = gdf.head(n).copy()
    if "geometry" in df.columns:
        df["geometry"] = df["geometry"].apply(lambda g: g.geom_type if isinstance(g, BaseGeometry) else "")
    cols = list(df.columns)[:max_cols]
    return pd.DataFrame(df[cols])


# =========================
# Helpers: Excel header guess + Coloring
# =========================
HEADER_HINTS = ["ä½æ‰€åœ°ç•ª", "ä½æ‰€", "åœ°ç•ª", "ç­†", "åœ°ç›®", "é¢ç©", "åœƒå ´", "è¾²åœ°", "å­—", "ç•ªåœ°"]
HYPHENS = r"[â€-â€’â€“â€”â€•ãƒ¼ï¼-]"

def to_half(s):
    return s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")) if isinstance(s, str) else s

def score_header_row(vals) -> int:
    score = 0
    for v in vals:
        s = str(v)
        score += 2 * sum(h in s for h in HEADER_HINTS)
        if 2 <= len(s) <= 12 and re.fullmatch(r"[^\d\s]{2,}", s or ""):
            score += 1
    return score

def suggest_header_rows(pre: pd.DataFrame, topk=6):
    n = min(40, len(pre))
    cand = sorted([(i, score_header_row(pre.iloc[i].values)) for i in range(n)],
                  key=lambda x: x[1], reverse=True)
    return [i for i, sc in cand[:topk] if sc > 0]

def is_good_header_choice(pre: pd.DataFrame, hdr_row: int, tmp_cols, cand_rows: List[int]) -> bool:
    if hdr_row in (cand_rows or []):
        return True
    try:
        row_score = score_header_row(pre.iloc[hdr_row].values)
    except Exception:
        row_score = 0
    has_addr_col = any(any(h in str(c) for h in ["ä½æ‰€åœ°ç•ª", "ä½æ‰€", "åœ°ç•ª"]) for c in tmp_cols)
    return (row_score >= 8) or has_addr_col

def style_header_preview(df: pd.DataFrame, good: bool):
    ok_bg = "rgba(0, 200, 83, 0.12)"
    ng_bg = "rgba(255, 82, 82, 0.12)"
    bg = ok_bg if good else ng_bg
    return (
        df.style.set_table_styles([
            {"selector": "thead th", "props": [("background-color", bg), ("font-weight", "700")]},
            {"selector": "tbody td", "props": [("background-color", bg)]},
        ])
    )


# =========================
# Helpers: label formatting (408 -> 408.0 ã‚’é˜²ã)
# =========================
def format_label(v) -> str:
    if v is None:
        return ""
    if isinstance(v, float):
        if pd.isna(v):
            return ""
        if v.is_integer():
            return str(int(v))
        s = str(v)
        return s.rstrip("0").rstrip(".")
    if isinstance(v, int):
        return str(v)
    s = str(v).strip()
    if re.fullmatch(r"-?\d+\.0+", s):
        return s.split(".")[0]
    return s


# =========================
# Helpers: Geo + Matching
# =========================
def ensure_wgs84(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    if gdf is None or gdf.empty:
        return gdf
    if gdf.crs is None:
        gdf = gdf.set_crs(epsg=4326, allow_override=True)
    else:
        gdf = gdf.to_crs(epsg=4326)
    return gdf

def dedupe_by_geometry(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    if gdf is None or gdf.empty or "geometry" not in gdf.columns:
        return gdf
    tmp = gdf.copy()
    tmp["__wkb"] = tmp.geometry.apply(lambda g: g.wkb_hex if isinstance(g, BaseGeometry) else None)
    tmp = tmp.drop_duplicates(subset=["__wkb"]).drop(columns=["__wkb"])
    return tmp

def read_geojson(files) -> gpd.GeoDataFrame:
    gdfs = []
    for f in files:
        g = gpd.read_file(f)
        g["source_file"] = f.name
        g = ensure_wgs84(g)
        gdfs.append(g)
    merged = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True), crs="EPSG:4326")
    return ensure_wgs84(merged)

def gdf_signature(gdf: gpd.GeoDataFrame, col_for_hash: Optional[str] = None) -> tuple:
    bounds = tuple(map(float, gdf.total_bounds)) if gdf is not None and not gdf.empty else (0, 0, 0, 0)
    n = int(len(gdf)) if gdf is not None else 0
    h = 0
    if gdf is not None and col_for_hash and col_for_hash in gdf.columns:
        try:
            h = int(pd.util.hash_pandas_object(gdf[col_for_hash].astype(str), index=False).sum())
        except Exception:
            h = 0
    return (n, bounds, h)

@st.cache_data(show_spinner=False)
def sjoin_pori_pin(_g_pori: gpd.GeoDataFrame, _g_pin: gpd.GeoDataFrame, pori_sig: tuple, pin_sig: tuple):
    try:
        j = gpd.sjoin(_g_pori, _g_pin, predicate="covers", how="left")
    except Exception:
        j = gpd.sjoin(_g_pori, _g_pin, predicate="intersects", how="left")
    return j.drop_duplicates()

def ensure_address_column(joined: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    if joined is None or joined.empty:
        return joined
    cols = set(joined.columns)
    if ADDRESS_COL_CANONICAL in cols:
        return joined
    if f"{ADDRESS_COL_CANONICAL}_left" in cols:
        joined[ADDRESS_COL_CANONICAL] = joined[f"{ADDRESS_COL_CANONICAL}_left"]
        return joined
    if f"{ADDRESS_COL_CANONICAL}_right" in cols:
        joined[ADDRESS_COL_CANONICAL] = joined[f"{ADDRESS_COL_CANONICAL}_right"]
        return joined
    return joined

def norm_addr_key(s: str, strip_last_num: bool = True) -> str:
    if not isinstance(s, str) or pd.isna(s):
        return ""
    s = to_half(s.strip()).lower().replace("ã€€", " ")
    s = re.sub(HYPHENS, "-", s)
    s = re.sub(r"\s+", "", s)
    s = s.replace("ä¸ç›®", "-").replace("ç•ªåœ°", "-").replace("ç•ª", "-").replace("å·", "")

    # âœ… æœ«å°¾ã®æç•ªï¼ˆ. , ã€ï¼‰ã‚’å‰Šé™¤ï¼ˆé€£ç¶šã‚‚OKï¼‰
    s = re.sub(r"(?:[\.ï¼,ï¼Œã€]\d{1,4})+$", "", s)

    # æ—¢å­˜ï¼šæœ«å°¾ã® -æ•°å­— ã‚’ç„¡è¦–ï¼ˆãƒã‚§ãƒƒã‚¯ONæ™‚ã®ã¿ï¼‰
    if strip_last_num:
        s = re.sub(r"-\d{1,4}$", "", s)

    return s

def addr_key_loose(k: str) -> str:
    s = re.sub(r"(æ±äº¬éƒ½|åŒ—æµ·é“|äº¬éƒ½åºœ|å¤§é˜ªåºœ|..çœŒ|..éƒ½|..é“|..åºœ)", "", k)
    return re.sub(r".{1,6}(å¸‚|åŒº|ç”º|æ‘)", "", s)

@st.cache_data(show_spinner=False)
def build_addr_dict(_gdf: gpd.GeoDataFrame, col: str, gdf_sig: tuple, strip_last_num: bool):
    t = _gdf[[col, "geometry"]].dropna(subset=[col, "geometry"]).copy()
    t["k1"] = t[col].astype(str).map(lambda s: norm_addr_key(s, strip_last_num=strip_last_num))
    t["k2"] = t["k1"].map(addr_key_loose)
    d1 = t.groupby("k1")["geometry"].first().to_dict()
    d2 = t.groupby("k2")["geometry"].first().to_dict()
    return d1, d2

def apply_match(df: pd.DataFrame, excel_addr_col: str, d1: dict, d2: dict, strip_last_num: bool) -> pd.DataFrame:
    out = df.copy()
    out["__k"] = out[excel_addr_col].astype(str).map(lambda s: norm_addr_key(s, strip_last_num=strip_last_num))

    # ä¸€æ—¦Shapelyã‚’ä½œã‚‹ï¼ˆæœ€å¾Œã«å¿…ãšæ¶ˆã™ï¼‰
    out["geom"] = out["__k"].map(d1)
    miss = out["geom"].isna()
    out.loc[miss, "geom"] = out.loc[miss, "__k"].map(addr_key_loose).map(d2)

    out["match_status"] = out["geom"].apply(lambda g: "ä¸€è‡´" if isinstance(g, BaseGeometry) else "ä¸€è‡´ãªã—")
    out["geometry_wkt"] = out["geom"].apply(lambda g: g.wkt if isinstance(g, BaseGeometry) else "")

    # âœ… JSON/SHAPEã§è½ã¡ã‚‹åŸå› ã‚’é™¤å»
    out = out.drop(columns=["__k", "geom"], errors="ignore")
    return out

def safe_load_wkt(wkt_str):
    if not isinstance(wkt_str, str) or not wkt_str.strip():
        return None
    try:
        return wkt_loads(wkt_str)
    except (WKTReadingError, UnicodeDecodeError, ValueError):
        return None

def safe_centroid_lonlat(gdf: gpd.GeoDataFrame) -> Tuple[float, float]:
    if gdf is None or gdf.empty:
        return (35.681236, 139.767125)
    try:
        g3857 = gdf.to_crs(epsg=3857)
        cent = g3857.geometry.centroid
        cent = gpd.GeoSeries(cent, crs="EPSG:3857").to_crs(epsg=4326)
        return (float(cent.y.mean()), float(cent.x.mean()))
    except Exception:
        b = gdf.total_bounds
        return (float((b[1] + b[3]) / 2), float((b[0] + b[2]) / 2))

def shp_safe_columns(cols: List[str]) -> Dict[str, str]:
    used = set()
    mapping = {}
    for c in cols:
        base = re.sub(r"[^0-9a-zA-Z_]", "_", str(c))
        base = base[:10] if base else "COL"
        name = base
        i = 2
        while name.upper() in used or not name:
            suffix = str(i)
            name = (base[: max(0, 10 - len(suffix))] + suffix)[:10]
            i += 1
        used.add(name.upper())
        mapping[c] = name
    return mapping

def gdf_to_shapefile_zip_bytes(gdf: gpd.GeoDataFrame, filename_prefix: str = "houjou_data") -> bytes:
    with tempfile.TemporaryDirectory() as tmpdir:
        shp_path = f"{tmpdir}/{filename_prefix}.shp"
        gdf.to_file(shp_path, driver="ESRI Shapefile", encoding="UTF-8")
        bio = BytesIO()
        with zipfile.ZipFile(bio, "w", zipfile.ZIP_DEFLATED) as zf:
            for ext in [".shp", ".shx", ".dbf", ".prj", ".cpg"]:
                p = f"{tmpdir}/{filename_prefix}{ext}"
                try:
                    with open(p, "rb") as f:
                        zf.writestr(f"{filename_prefix}{ext}", f.read())
                except FileNotFoundError:
                    pass
        bio.seek(0)
        return bio.read()


# =========================
# Step status
# =========================
def is_ready(obj) -> bool:
    return obj is not None and not (hasattr(obj, "empty") and obj.empty)

s1 = is_ready(st.session_state.merged_pori) and is_ready(st.session_state.merged_pins)
s2 = is_ready(st.session_state.joined) and (
    ADDRESS_COL_CANONICAL in st.session_state.joined.columns if is_ready(st.session_state.joined) else False
)
s3 = is_ready(st.session_state.matched)


# =========================
# Sidebar (çŠ¶æ…‹è¡¨ç¤º + ãƒªã‚»ãƒƒãƒˆã®ã¿)
# =========================
st.sidebar.markdown("<div class='sidebar-title'>ç¾åœ¨ã®çŠ¶æ…‹</div>", unsafe_allow_html=True)
st.sidebar.markdown(f"<div class='sidebar-item'>â‘  çµåˆï¼š{'âœ…' if s1 else 'â€”'}</div>", unsafe_allow_html=True)
st.sidebar.markdown(f"<div class='sidebar-item'>â‘¡ ç©ºé–“çµåˆï¼š{'âœ…' if s2 else 'â€”'}</div>", unsafe_allow_html=True)
st.sidebar.markdown(f"<div class='sidebar-item'>â‘¢ ä½æ‰€ç…§åˆï¼š{'âœ…' if s3 else 'â€”'}</div>", unsafe_allow_html=True)

if s3:
    m = st.session_state.matched
    ok = int((m["match_status"] == "ä¸€è‡´").sum())
    tot = int(len(m))
    st.sidebar.markdown("<div class='hr'></div>", unsafe_allow_html=True)
    st.sidebar.write(f"ä¸€è‡´: {ok:,} / {tot:,}ï¼ˆ{(ok/tot if tot else 0):.1%}ï¼‰")

st.sidebar.markdown("<div class='hr'></div>", unsafe_allow_html=True)
if st.sidebar.button("ğŸ” ã™ã¹ã¦ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
    reset_all()
    st.rerun()


# =========================
# Header
# =========================
st.title("ç­†ãƒãƒªã‚´ãƒ³Ã—ãƒ”ãƒ³ï¼šç…§åˆâ†’åœ°å›³â†’å‡ºåŠ›ï¼ˆ1ãƒšãƒ¼ã‚¸ï¼‰")
st.caption("çµ±åˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯ st.table ã‚’ä½¿ç”¨ã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰/æœ€å¤§åŒ–ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã—ã¾ã›ã‚“ã€‚å‡ºåŠ›ã¯ Shapefile ã®ã¿ã§ã™ã€‚")
steps_done = sum([1 if s1 else 0, 1 if s2 else 0, 1 if s3 else 0])
st.progress(steps_done / 3 if 3 else 0)


# =========================
# Main
# =========================
if st.session_state.upload_error:
    st.error(st.session_state.upload_error)

# ---- Step 1 ----
st.markdown(
    "<div class='step'>"
    "<div class='step-title'>Step 1ï½œGeoJSONã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</div>"
    "<div class='step-desc'>æŒ‡å®šã®æ–‡å­—åˆ—ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã¾ãªã„å ´åˆã¯ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒè‡ªå‹•ã§ã‚¯ãƒªã‚¢ã•ã‚Œã¾ã™ã€‚</div>"
    "</div>",
    unsafe_allow_html=True
)

u1, u2 = st.columns(2, gap="large")

with u1:
    st.markdown("**ç­†ãƒãƒªã‚´ãƒ³ GeoJSONï¼ˆè¤‡æ•°å¯ï¼‰**")
    pori_files = st.file_uploader(
        "ãƒ•ã‚¡ã‚¤ãƒ«åã«ã€Œç­†ãƒãƒªã‚´ãƒ³ã€ã‚’å«ã‚€ GeoJSON ã®ã¿",
        type=["geojson"],
        accept_multiple_files=True,
        key=f"pori_files_{st.session_state.uploader_nonce}",
    )
    validate_filename_or_reset(pori_files, ["ç­†ãƒãƒªã‚´ãƒ³"], "ç­†ãƒãƒªã‚´ãƒ³ GeoJSON")

with u2:
    st.markdown("**ãƒ”ãƒ³ GeoJSONï¼ˆè¤‡æ•°å¯ï¼‰**")
    pin_files = st.file_uploader(
        "ãƒ•ã‚¡ã‚¤ãƒ«åã«ã€Œè¾²åœ°ãƒ”ãƒ³ã€ã¾ãŸã¯ã€Œè¾²å ´ãƒ”ãƒ³ã€ã‚’å«ã‚€ GeoJSON ã®ã¿",
        type=["geojson"],
        accept_multiple_files=True,
        key=f"pin_files_{st.session_state.uploader_nonce}",
    )
    validate_filename_or_reset(pin_files, ["è¾²åœ°ãƒ”ãƒ³", "è¾²å ´ãƒ”ãƒ³"], "ãƒ”ãƒ³ GeoJSON")

if st.session_state.upload_error and files_ok(pori_files, ["ç­†ãƒãƒªã‚´ãƒ³"]) and files_ok(pin_files, ["è¾²åœ°ãƒ”ãƒ³", "è¾²å ´ãƒ”ãƒ³"]):
    st.session_state.upload_error = None

st.markdown("<div class='hr'></div>", unsafe_allow_html=True)

# ---- Step 2 ----
st.markdown(
    "<div class='step'>"
    "<div class='step-title'>Step 2ï½œçµåˆ â†’ ç©ºé–“çµåˆ</div>"
    "<div class='step-desc'>CRSã‚’çµ±ä¸€ã—ã€é‡è¤‡ã‚’å‰Šé™¤ã—ã¦ã‹ã‚‰ç©ºé–“çµåˆã—ã¾ã™ã€‚ä½æ‰€ã¯ç©ºé–“çµåˆçµæœã® <b>Address</b> ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚</div>"
    "</div>",
    unsafe_allow_html=True
)

can_merge = bool(pori_files) and bool(pin_files)
colA, colB = st.columns([1.2, 1], gap="large")

with colA:
    merge_clicked = st.button("ğŸ”„ çµåˆã™ã‚‹ï¼ˆCRSçµ±ä¸€ + é‡è¤‡å‰Šé™¤ï¼‰", use_container_width=True, disabled=not can_merge)
    if merge_clicked:
        with st.spinner("çµåˆä¸­â€¦"):
            g_pori = dedupe_by_geometry(read_geojson(pori_files))
            g_pin = dedupe_by_geometry(read_geojson(pin_files))
            st.session_state.merged_pori = g_pori
            st.session_state.merged_pins = g_pin
            st.session_state.joined = None
            st.session_state.matched = None
        st.success(f"âœ… çµåˆå®Œäº†ï¼šç­†ãƒãƒªã‚´ãƒ³ {len(g_pori):,}ä»¶ / ãƒ”ãƒ³ {len(g_pin):,}ä»¶")

    if is_ready(st.session_state.merged_pori):
        with st.expander("çµ±åˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆç­†ãƒãƒªã‚´ãƒ³ãƒ»å…ˆé ­5ä»¶ï¼‰", expanded=False):
            st.table(slim_gdf_preview(st.session_state.merged_pori, n=5))
    if is_ready(st.session_state.merged_pins):
        with st.expander("çµ±åˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ”ãƒ³ãƒ»å…ˆé ­5ä»¶ï¼‰", expanded=False):
            st.table(slim_gdf_preview(st.session_state.merged_pins, n=5))

with colB:
    can_sjoin = is_ready(st.session_state.merged_pori) and is_ready(st.session_state.merged_pins)
    sjoin_clicked = st.button("ğŸ§© ç©ºé–“çµåˆã™ã‚‹ï¼ˆç­†ãƒãƒªã‚´ãƒ³ Ã— ãƒ”ãƒ³ï¼‰", use_container_width=True, disabled=not can_sjoin)
    if sjoin_clicked:
        with st.spinner("ç©ºé–“çµåˆä¸­â€¦"):
            pori_sig = gdf_signature(st.session_state.merged_pori)
            pin_sig = gdf_signature(st.session_state.merged_pins)
            joined = sjoin_pori_pin(st.session_state.merged_pori, st.session_state.merged_pins, pori_sig, pin_sig)
            joined = ensure_address_column(joined)
            st.session_state.joined = joined
            st.session_state.matched = None

        if ADDRESS_COL_CANONICAL not in st.session_state.joined.columns:
            st.error("ç©ºé–“çµåˆçµæœã« Address åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆAddress_left/right ã‚‚ç„¡ã—ï¼‰ã€‚")
            st.write("æ¤œå‡ºåˆ—:", list(st.session_state.joined.columns))
        else:
            st.success("âœ… ç©ºé–“çµåˆå®Œäº†ï¼ˆä½æ‰€ã‚«ãƒ©ãƒ ï¼šAddressï¼‰")

    if is_ready(st.session_state.joined):
        with st.expander("ç©ºé–“çµåˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­5ä»¶ï¼‰", expanded=False):
            st.table(slim_gdf_preview(st.session_state.joined, n=5))

st.markdown("<div class='hr'></div>", unsafe_allow_html=True)

# ---- Step 3 ----
st.markdown(
    "<div class='step'>"
    "<div class='step-title'>Step 3ï½œExcelã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œãƒ»ä½æ‰€åˆ—ã‚’è¨­å®šï¼‰</div>"
    "<div class='step-desc'>ãƒ˜ãƒƒãƒ€ãƒ¼ãŒåˆã£ã¦ã„ãã†ãªã‚‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒç·‘ã«ãªã‚Šã¾ã™ã€‚</div>"
    "</div>",
    unsafe_allow_html=True
)

f_xlsx = st.file_uploader("åœƒå ´ç™»éŒ²ä»£è¡Œã‚·ãƒ¼ãƒˆï¼ˆExcelï¼‰", type=["xlsx", "xls"], key="xlsx")

st.session_state.strip_last_num = st.checkbox(
    "æœ«å°¾ã®æç•ªï¼ˆ-æ•°å­—ï¼‰ã‚’ç„¡è¦–ã—ã¦ç…§åˆï¼ˆ. / , / ã€ ã®æç•ªã¯å¸¸ã«å‰Šé™¤ï¼‰",
    value=bool(st.session_state.strip_last_num),
)

cand = []
if f_xlsx:
    h = hash(f_xlsx.getvalue())
    if st.session_state.excel_hash != h:
        st.session_state.update({"sheet_name": None, "header_row": None, "excel_hash": h, "excel_addr_col": None})
        st.session_state.matched = None

    try:
        xls = pd.ExcelFile(f_xlsx)
        sheets = xls.sheet_names
    except Exception as e:
        st.error(f"Excelã®ã‚·ãƒ¼ãƒˆå–å¾—ã«å¤±æ•—: {e}")
        sheets = []

    if sheets:
        st.session_state.sheet_name = st.selectbox(
            "ã‚·ãƒ¼ãƒˆå",
            sheets,
            index=0 if st.session_state.sheet_name not in sheets else sheets.index(st.session_state.sheet_name),
        )

        pre = pd.read_excel(f_xlsx, sheet_name=st.session_state.sheet_name, header=None, nrows=40)
        st.caption("Excelãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®40è¡Œï¼‰")
        st.dataframe(pre, use_container_width=True, height=260)

        cand = suggest_header_rows(pre)
        default_header = cand[0] if cand else 0

        c1, c2 = st.columns([1, 1.6], gap="large")
        with c1:
            hdr = st.number_input(
                "ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆ0å§‹ã¾ã‚Šï¼‰",
                min_value=0, max_value=len(pre) - 1,
                value=st.session_state.header_row if st.session_state.header_row is not None else int(default_header),
                step=1,
            )
            if cand:
                pick = st.radio("å€™è£œï¼ˆãŠã™ã™ã‚ï¼‰", options=cand, index=0, format_func=lambda i: f"è¡Œ {i}")
                hdr = pick
            st.session_state.header_row = int(hdr)

        with c2:
            try:
                tmp = pd.read_excel(
                    f_xlsx,
                    sheet_name=st.session_state.sheet_name,
                    header=st.session_state.header_row,
                    nrows=10,
                )
                good_hdr = is_good_header_choice(pre, st.session_state.header_row, list(tmp.columns), cand)

                st.caption("ãƒ˜ãƒƒãƒ€ãƒ¼é©ç”¨å¾Œãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(style_header_preview(tmp, good_hdr), use_container_width=True, height=220)

                excel_candidates = [c for c in tmp.columns if any(h in str(c) for h in ["ä½æ‰€åœ°ç•ª", "ä½æ‰€", "åœ°ç•ª"])]
                if st.session_state.excel_addr_col not in list(tmp.columns):
                    st.session_state.excel_addr_col = excel_candidates[0] if excel_candidates else list(tmp.columns)[0]

                st.session_state.excel_addr_col = st.selectbox(
                    "ä½æ‰€åˆ—ï¼ˆExcelå´ï¼‰",
                    options=list(tmp.columns),
                    index=list(tmp.columns).index(st.session_state.excel_addr_col)
                    if st.session_state.excel_addr_col in list(tmp.columns) else 0,
                )
            except Exception as e:
                st.error(f"ãƒ˜ãƒƒãƒ€ãƒ¼é©ç”¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã‚¨ãƒ©ãƒ¼: {e}")

st.markdown("<div class='hr'></div>", unsafe_allow_html=True)

# ---- Step 4 ----
st.markdown(
    "<div class='step'>"
    "<div class='step-title'>Step 4ï½œä½æ‰€ç…§åˆï¼ˆExcel â†’ ç­†ãƒãƒªã‚´ãƒ³ï¼‰</div>"
    "<div class='step-desc'>ç©ºé–“çµåˆçµæœã® <b>Address</b> ã‚’è¾æ›¸åŒ–ã—ã¦ã€Excelã®ä½æ‰€ã«ãƒãƒªã‚´ãƒ³geometryã‚’ä»˜ä¸ã—ã¾ã™ã€‚</div>"
    "</div>",
    unsafe_allow_html=True
)

can_match = (
    is_ready(st.session_state.joined)
    and (ADDRESS_COL_CANONICAL in st.session_state.joined.columns)
    and (f_xlsx is not None)
    and (st.session_state.sheet_name is not None)
    and (st.session_state.header_row is not None)
    and (st.session_state.excel_addr_col is not None)
)

match_clicked = st.button("ğŸš€ ä½æ‰€ç…§åˆã‚’å®Ÿè¡Œ", use_container_width=True, disabled=not can_match)

if match_clicked:
    excel_addr = st.session_state.excel_addr_col
    with st.spinner("ç…§åˆä¸­â€¦"):
        # æ–‡å­—åˆ—ã§èª­ã¿è¾¼ã¿ï¼ˆ408.0å•é¡Œã®æ ¹æœ¬å¯¾ç­–ï¼‰
        df = pd.read_excel(
            f_xlsx,
            sheet_name=st.session_state.sheet_name,
            header=st.session_state.header_row,
            dtype=str,
        )
        if excel_addr not in df.columns:
            st.error("é¸æŠã—ãŸä½æ‰€åˆ—ãŒExcelã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            st.stop()

        before = len(df)
        df = df.dropna(subset=[excel_addr]).copy()
        dropped = before - len(df)

        sig = gdf_signature(st.session_state.joined, ADDRESS_COL_CANONICAL)
        d1, d2 = build_addr_dict(
            st.session_state.joined,
            ADDRESS_COL_CANONICAL,
            sig,
            bool(st.session_state.strip_last_num),
        )
        matched = apply_match(df, excel_addr, d1, d2, bool(st.session_state.strip_last_num))
        st.session_state.matched = matched

    if dropped > 0:
        st.info(f"ä½æ‰€ãŒç©ºã® {dropped:,} ä»¶ã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚")
    st.success("âœ… ä½æ‰€ç…§åˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# ---- Step 5 ----
if is_ready(st.session_state.matched):
    m = st.session_state.matched
    ok = int((m["match_status"] == "ä¸€è‡´").sum())
    tot = int(len(m))
    ng = tot - ok
    rate = ok / tot if tot else 0

    k1, k2, k3 = st.columns(3)
    with k1:
        st.markdown(f"<div class='kpi'><b>ä¸€è‡´</b><br>{ok:,}</div>", unsafe_allow_html=True)
    with k2:
        st.markdown(f"<div class='kpi'><b>æœªä¸€è‡´</b><br>{ng:,}</div>", unsafe_allow_html=True)
    with k3:
        st.markdown(f"<div class='kpi'><b>ä¸€è‡´ç‡</b><br>{rate:.1%}</div>", unsafe_allow_html=True)

    st.markdown("### çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­20è¡Œï¼‰")
    st.dataframe(m.head(20), use_container_width=True)

    st.markdown("<div class='hr'></div>", unsafe_allow_html=True)
    st.markdown(
        "<div class='step'>"
        "<div class='step-title'>Step 5ï½œåœ°å›³è¡¨ç¤º & å‡ºåŠ›ï¼ˆShapefileã®ã¿ï¼‰</div>"
        "<div class='step-desc'>ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡ã«ã—ã¾ã™ã€‚åœ°å›³ä¸Šã«åœƒå ´åãƒ©ãƒ™ãƒ«ï¼ˆæ–‡å­—ã‚µã‚¤ã‚º16å›ºå®šï¼‰ã‚’è¡¨ç¤ºã§ãã¾ã™ã€‚</div>"
        "</div>",
        unsafe_allow_html=True
    )

    st.session_state.show_map = st.checkbox("ğŸ—ºï¸ åœ°å›³ã‚’è¡¨ç¤ºã™ã‚‹ï¼ˆé‡ã„å ´åˆã¯OFFï¼‰", value=bool(st.session_state.show_map))

    mg = m[m["match_status"] == "ä¸€è‡´"].copy()
    mg["geometry"] = mg["geometry_wkt"].apply(safe_load_wkt)
    mg = mg.dropna(subset=["geometry"])
    gdf = gpd.GeoDataFrame(mg, geometry="geometry", crs="EPSG:4326")

    if gdf.empty:
        st.warning("ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ãŒç„¡ã„ãŸã‚ã€åœ°å›³è¡¨ç¤ºãƒ»å‡ºåŠ›ã¯ã§ãã¾ã›ã‚“ã€‚")
    else:
        label_candidates = ["åœƒå ´å", "FieldName", "field_name", "name", "åœƒå ´", "åœƒå ´ID", "FieldID"]
        label_col = next((c for c in label_candidates if c in gdf.columns), None)

        if st.session_state.show_map:
            lat, lon = safe_centroid_lonlat(gdf)
            mp = folium.Map(location=[lat, lon], zoom_start=14)

            gdf_map = gdf.drop(columns=["geometry_wkt"], errors="ignore")
            excel_addr = st.session_state.excel_addr_col
            tooltip_fields = [excel_addr] if excel_addr in gdf_map.columns else []

            folium.GeoJson(
                gdf_map.__geo_interface__,
                tooltip=folium.features.GeoJsonTooltip(fields=tooltip_fields) if tooltip_fields else None,
            ).add_to(mp)

            if label_col:
                default_on = len(gdf) <= 200
                show_labels = st.checkbox(f"ğŸ·ï¸ åœƒå ´åãƒ©ãƒ™ãƒ«ã‚’è¡¨ç¤ºï¼ˆåˆ—: {label_col}ï¼‰", value=default_on)

                if show_labels:
                    for _, row in gdf.iterrows():
                        label = format_label(row.get(label_col, ""))
                        if not label:
                            continue
                        p = row.geometry.representative_point()
                        folium.Marker(
                            location=[p.y, p.x],
                            icon=folium.DivIcon(
                                html=(
                                    f"<div style="
                                    f"'font-size:{LABEL_FONT_SIZE}px;"
                                    f"font-weight:700;"
                                    f"color:#111;"
                                    f"background:rgba(255,255,255,0.75);"
                                    f"padding:1px 4px;"
                                    f"border-radius:6px;"
                                    f"border:1px solid rgba(0,0,0,0.15);"
                                    f"white-space:nowrap;'>"
                                    f"{html.escape(label)}"
                                    f"</div>"
                                )
                            ),
                        ).add_to(mp)

            minx, miny, maxx, maxy = gdf.total_bounds
            mp.fit_bounds([[miny, minx], [maxy, maxx]])
            folium_static(mp, width=1100, height=650)

        st.markdown("### å‡ºåŠ›ï¼ˆShapefile ZIPï¼‰")
        out_prefix = st.text_input("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ãªã—ï¼‰", value="houjou_data")

        attr_cols = [c for c in gdf.columns if c != "geometry"]
        mapping = shp_safe_columns(attr_cols)
        gdf_shp = gdf.rename(columns=mapping)

        shp_bytes = gdf_to_shapefile_zip_bytes(gdf_shp, filename_prefix=out_prefix)

        st.download_button(
            "ğŸ“¥ Shapefileï¼ˆZIPï¼‰",
            data=shp_bytes,
            file_name=f"{out_prefix}.zip",
            mime="application/zip",
            use_container_width=True,
        )

        st.caption("â€» Shapefileã¯åˆ—å10æ–‡å­—åˆ¶ç´„ã®ãŸã‚ã€åˆ—åã¯è‡ªå‹•ã§è‹±æ•°å­—10æ–‡å­—ä»¥å†…ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚")
else:
    st.info("Step 4 ã®ã€Œä½æ‰€ç…§åˆã‚’å®Ÿè¡Œã€ã‚’æŠ¼ã™ã¨ã€ã“ã“ã«åœ°å›³ã¨å‡ºåŠ›ï¼ˆShapefileï¼‰ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
