# streamlit_app.py
# pip install streamlit geopandas shapely folium streamlit-folium rtree openpyxl


import re
import unicodedata
import zipfile
import tempfile
import html
from io import BytesIO
from typing import List, Optional, Tuple


import pandas as pd
import geopandas as gpd
import streamlit as st
import folium
from shapely.geometry.base import BaseGeometry
from shapely.wkt import loads as wkt_loads
from shapely.errors import WKTReadingError
from streamlit_folium import folium_static




# =========================================================
# Config
# =========================================================
st.set_page_config(page_title="ç­†ãƒãƒªã‚´ãƒ³Ã—ãƒ”ãƒ³ï¼šä½æ‰€ç…§åˆâ†’åœ°å›³â†’å‡ºåŠ›", layout="wide")


ADDRESS_COL_CANONICAL = "Address"   # ç©ºé–“çµåˆå¾Œã«ä½¿ã†ä½æ‰€åˆ—ã¯ Address å›ºå®š
LABEL_FONT_SIZE = 16               # ãƒ©ãƒ™ãƒ«æ–‡å­—ã‚µã‚¤ã‚ºå›ºå®šï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ç„¡ã—ï¼‰




# =========================================================
# Session State
# =========================================================
STATE_DEFAULTS = {
    "merged_pori": None,
    "merged_pins": None,
    "joined": None,
    "matched": None,
    "excel_hash": None,
    "sheet_name": None,
    "header_row": None,
    "excel_addr_col": None,
    "field_name_col": None,
    "strip_last_num": True,     # æœ«å°¾ã® -æ•°å­— ã‚’ç„¡è¦–ï¼ˆ. , ã€æç•ªã¯å¸¸ã«å‰Šé™¤ï¼‰
    "show_map": False,
    "uploader_nonce": 0,        # uploaderå¼·åˆ¶ãƒªã‚»ãƒƒãƒˆç”¨
    "upload_error": None,       # ç›´è¿‘ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ¶ç´„é•åãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
}
for k, v in STATE_DEFAULTS.items():
    st.session_state.setdefault(k, v)




# =========================================================
# Styles
# =========================================================
CSS = """
<style>
:root{
  --muted: rgba(130,130,130,.9);
  --card: rgba(255,255,255,.04);
  --card2: rgba(255,255,255,.06);
  --border: rgba(255,255,255,.10);
  --ok: rgba(0, 200, 83, .18);
  --ng: rgba(255, 82, 82, .18);
}
.block-container{padding-top: 1.1rem;}
h1,h2,h3{letter-spacing: .2px;}
.hr{height:1px; background: var(--border); margin: 1.1rem 0;}
.step{
  padding: .75rem .95rem; border: 1px solid var(--border); border-radius: 16px;
  background: var(--card); margin-bottom: .85rem;
}
.step-head{display:flex; align-items:center; justify-content:space-between; gap: .6rem;}
.step-title{font-size:1.06rem; font-weight:800; margin: 0;}
.step-desc{color:var(--muted); font-size:.92rem; margin:.35rem 0 0;}
.badge{
  padding: .18rem .55rem; border-radius: 999px; font-size:.78rem; font-weight:700;
  border: 1px solid var(--border); background: rgba(255,255,255,.04);
  white-space: nowrap;
}
.badge-ok{background: var(--ok);}
.badge-ng{background: var(--ng);}
.kpi{
  padding:.65rem .8rem; border:1px solid var(--border); border-radius: 14px;
  background: var(--card2);
}
.sidebar-title{font-weight:900; margin-bottom:.35rem;}
.sidebar-item{margin:.35rem 0; color: rgba(220,220,220,.95);}
.small{color: var(--muted); font-size:.88rem;}
</style>
"""
st.markdown(CSS, unsafe_allow_html=True)




# =========================================================
# Utilities
# =========================================================
HEADER_HINTS = ["ä½æ‰€åœ°ç•ª", "ä½æ‰€", "åœ°ç•ª", "ç­†", "åœ°ç›®", "é¢ç©", "åœƒå ´", "è¾²åœ°", "å­—", "ç•ªåœ°"]
HYPHENS = r"[â€-â€’â€“â€”â€•ãƒ¼ï¼-]"




def reset_all():
    for k in list(STATE_DEFAULTS.keys()):
        st.session_state[k] = STATE_DEFAULTS[k]




def step_card_render(slot, title: str, desc: str, done: bool):
    badge = "<span class='badge badge-ok'>âœ… å®Œäº†</span>" if done else "<span class='badge badge-ng'>â³ æœªå®Œ</span>"
    slot.markdown(
        f"""
        <div class="step">
          <div class="step-head">
            <div class="step-title">{html.escape(title)}</div>
            {badge}
          </div>
          <div class="step-desc">{desc}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )




def norm_filename(s: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«åæ¯”è¼ƒç”¨ï¼šNFKC + ç©ºç™½é™¤å»"""
    s = unicodedata.normalize("NFKC", s or "")
    s = s.replace("ã€€", " ")
    s = re.sub(r"\s+", "", s)
    return s




def fail_upload(offending_name: str, label: str, allow_words: List[str]):
    allow = " / ".join(allow_words)
    st.session_state.upload_error = (
        f"âŒ {label} ã¯ãƒ•ã‚¡ã‚¤ãƒ«åã«ã€Œ{allow}ã€ã‚’å«ã‚€ GeoJSON ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚\n\n"
        f"- é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {offending_name}\n"
        f"- å¯¾å¿œ: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¬„ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚æ­£ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸ã³ç›´ã—ã¦ãã ã•ã„ã€‚"
    )
    st.session_state.uploader_nonce += 1  # keyã‚’å¤‰ãˆã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’å¼·åˆ¶ã‚¯ãƒªã‚¢
    st.rerun()




def validate_filename_or_reset(files, must_include_any: List[str], label: str):
    """é¸æŠå¾Œã«å³æ ¼ãƒã‚§ãƒƒã‚¯ã—ã¦é•åãªã‚‰å³ãƒªã‚»ãƒƒãƒˆ"""
    if not files:
        return
    musts = [norm_filename(x) for x in must_include_any]
    for f in files:
        name_norm = norm_filename(f.name)
        if not any(m in name_norm for m in musts):
            fail_upload(f.name, label, must_include_any)




def is_ready(obj) -> bool:
    return obj is not None and not (hasattr(obj, "empty") and obj.empty)




def to_half(s):
    return s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")) if isinstance(s, str) else s




def score_header_row(vals) -> int:
    score = 0
    for v in vals:
        s = str(v)
        score += 2 * sum(h in s for h in HEADER_HINTS)
        if 2 <= len(s) <= 12 and re.fullmatch(r"[^\d\s]{2,}", s or ""):
            score += 1
    return score




def suggest_header_rows(pre: pd.DataFrame, topk=6):
    n = min(40, len(pre))
    cand = sorted([(i, score_header_row(pre.iloc[i].values)) for i in range(n)],
                  key=lambda x: x[1], reverse=True)
    return [i for i, sc in cand[:topk] if sc > 0]




def is_good_header_choice(pre: pd.DataFrame, hdr_row: int, tmp_cols, cand_rows: List[int]) -> bool:
    if hdr_row in (cand_rows or []):
        return True
    try:
        row_score = score_header_row(pre.iloc[hdr_row].values)
    except Exception:
        row_score = 0
    has_addr_col = any(any(h in str(c) for h in ["ä½æ‰€åœ°ç•ª", "ä½æ‰€", "åœ°ç•ª"]) for c in tmp_cols)
    return (row_score >= 8) or has_addr_col




def style_header_preview(df: pd.DataFrame, good: bool):
    ok_bg = "rgba(0, 200, 83, 0.12)"
    ng_bg = "rgba(255, 82, 82, 0.12)"
    bg = ok_bg if good else ng_bg
    return (
        df.style.set_table_styles([
            {"selector": "thead th", "props": [("background-color", bg), ("font-weight", "800")]},
            {"selector": "tbody td", "props": [("background-color", bg)]},
        ])
    )




def slim_gdf_preview(gdf: gpd.GeoDataFrame, n: int = 5, max_cols: int = 12) -> pd.DataFrame:
    """st.tableç”¨ï¼ˆãƒ„ãƒ¼ãƒ«ãƒãƒ¼ç„¡ã—ï¼‰"""
    if gdf is None or getattr(gdf, "empty", True):
        return pd.DataFrame()
    df = gdf.head(n).copy()
    if "geometry" in df.columns:
        df["geometry"] = df["geometry"].apply(lambda g: g.geom_type if isinstance(g, BaseGeometry) else "")
    cols = list(df.columns)[:max_cols]
    return pd.DataFrame(df[cols])




def ensure_wgs84(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    if gdf is None or gdf.empty:
        return gdf
    if gdf.crs is None:
        gdf = gdf.set_crs(epsg=4326, allow_override=True)
    else:
        gdf = gdf.to_crs(epsg=4326)
    return gdf




def dedupe_by_geometry(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    """ã‚¸ã‚ªãƒ¡ãƒˆãƒªé‡è¤‡ã‚’å‰Šé™¤ï¼ˆWKBã§æ¯”è¼ƒï¼‰"""
    if gdf is None or gdf.empty or "geometry" not in gdf.columns:
        return gdf
    tmp = gdf.copy()
    tmp["__wkb"] = tmp.geometry.apply(lambda g: g.wkb_hex if isinstance(g, BaseGeometry) else None)
    tmp = tmp.drop_duplicates(subset=["__wkb"]).drop(columns=["__wkb"])
    return tmp




def read_geojson(files) -> gpd.GeoDataFrame:
    gdfs = []
    for f in files:
        g = gpd.read_file(f)
        g["source_file"] = f.name
        g = ensure_wgs84(g)
        gdfs.append(g)
    merged = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True), crs="EPSG:4326")
    return ensure_wgs84(merged)




def gdf_signature(gdf: gpd.GeoDataFrame, col_for_hash: Optional[str] = None) -> tuple:
    bounds = tuple(map(float, gdf.total_bounds)) if gdf is not None and not gdf.empty else (0, 0, 0, 0)
    n = int(len(gdf)) if gdf is not None else 0
    h = 0
    if gdf is not None and col_for_hash and col_for_hash in gdf.columns:
        try:
            h = int(pd.util.hash_pandas_object(gdf[col_for_hash].astype(str), index=False).sum())
        except Exception:
            h = 0
    return (n, bounds, h)




@st.cache_data(show_spinner=False)
def sjoin_pori_pin(_g_pori: gpd.GeoDataFrame, _g_pin: gpd.GeoDataFrame, pori_sig: tuple, pin_sig: tuple):
    try:
        j = gpd.sjoin(_g_pori, _g_pin, predicate="covers", how="left")
    except Exception:
        j = gpd.sjoin(_g_pori, _g_pin, predicate="intersects", how="left")
    return j.drop_duplicates()




def ensure_address_column(joined: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    """Address / Address_left / Address_right ã‚’ Address ã«æ­£è¦åŒ–"""
    if joined is None or joined.empty:
        return joined
    cols = set(joined.columns)
    if ADDRESS_COL_CANONICAL in cols:
        return joined
    if f"{ADDRESS_COL_CANONICAL}_left" in cols:
        joined[ADDRESS_COL_CANONICAL] = joined[f"{ADDRESS_COL_CANONICAL}_left"]
        return joined
    if f"{ADDRESS_COL_CANONICAL}_right" in cols:
        joined[ADDRESS_COL_CANONICAL] = joined[f"{ADDRESS_COL_CANONICAL}_right"]
        return joined
    return joined




def norm_addr_key(s: str, strip_last_num: bool = True) -> str:
    """ä½æ‰€ã®ç…§åˆã‚­ãƒ¼åŒ–ï¼š
    - å…¨è§’â†’åŠè§’æ•°å­—
    - ãƒã‚¤ãƒ•ãƒ³é¡ã‚’çµ±ä¸€
    - ç©ºç™½é™¤å»
    - æœ«å°¾ã® . , ã€ ã®æç•ªã‚’å‰Šé™¤ï¼ˆå¸¸ã«ï¼‰
    - æœ«å°¾ã® -æ•°å­— ã‚’å‰Šé™¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    if not isinstance(s, str) or pd.isna(s):
        return ""
    s = to_half(s.strip()).lower().replace("ã€€", " ")
    s = re.sub(HYPHENS, "-", s)
    s = re.sub(r"\s+", "", s)
    s = s.replace("ä¸ç›®", "-").replace("ç•ªåœ°", "-").replace("ç•ª", "-").replace("å·", "")


    # æœ«å°¾ã®æç•ªï¼ˆ. , ã€ï¼‰ã‚’å‰Šé™¤ï¼ˆé€£ç¶šã‚‚OKï¼‰
    s = re.sub(r"(?:[\.ï¼,ï¼Œã€]\d{1,4})+$", "", s)


    # æœ«å°¾ã® -æ•°å­— ã‚’ç„¡è¦–ï¼ˆä»»æ„ï¼‰
    if strip_last_num:
        s = re.sub(r"-\d{1,4}$", "", s)


    return s




def addr_key_loose(k: str) -> str:
    s = re.sub(r"(æ±äº¬éƒ½|åŒ—æµ·é“|äº¬éƒ½åºœ|å¤§é˜ªåºœ|..çœŒ|..éƒ½|..é“|..åºœ)", "", k)
    return re.sub(r".{1,6}(å¸‚|åŒº|ç”º|æ‘)", "", s)




@st.cache_data(show_spinner=False)
def build_addr_dict(_gdf: gpd.GeoDataFrame, col: str, gdf_sig: tuple, strip_last_num: bool):
    t = _gdf[[col, "geometry"]].dropna(subset=[col, "geometry"]).copy()
    t["k1"] = t[col].astype(str).map(lambda s: norm_addr_key(s, strip_last_num=strip_last_num))
    t["k2"] = t["k1"].map(addr_key_loose)
    d1 = t.groupby("k1")["geometry"].first().to_dict()
    d2 = t.groupby("k2")["geometry"].first().to_dict()
    return d1, d2




def apply_match(df: pd.DataFrame, excel_addr_col: str, d1: dict, d2: dict, strip_last_num: bool) -> pd.DataFrame:
    out = df.copy()
    out["__k"] = out[excel_addr_col].astype(str).map(lambda s: norm_addr_key(s, strip_last_num=strip_last_num))


    # ä¸€æ—¦Shapelyã‚’ä½œã‚‹ï¼ˆæœ€å¾Œã«å¿…ãšæ¶ˆã™ï¼‰
    out["geom"] = out["__k"].map(d1)
    miss = out["geom"].isna()
    out.loc[miss, "geom"] = out.loc[miss, "__k"].map(addr_key_loose).map(d2)


    out["match_status"] = out["geom"].apply(lambda g: "ä¸€è‡´" if isinstance(g, BaseGeometry) else "ä¸€è‡´ãªã—")
    out["geometry_wkt"] = out["geom"].apply(lambda g: g.wkt if isinstance(g, BaseGeometry) else "")


    # JSON/SHAPEã§è½ã¡ã‚‹åŸå› ï¼ˆshapelyåˆ—ï¼‰ã‚’é™¤å»
    out = out.drop(columns=["__k", "geom"], errors="ignore")
    return out




def safe_load_wkt(wkt_str):
    if not isinstance(wkt_str, str) or not wkt_str.strip():
        return None
    try:
        return wkt_loads(wkt_str)
    except (WKTReadingError, UnicodeDecodeError, ValueError):
        return None




def safe_centroid_lonlat(gdf: gpd.GeoDataFrame) -> Tuple[float, float]:
    """åœ°å›³ä¸­å¿ƒã®è¨ˆç®—ï¼ˆcentroidã®è­¦å‘Šå›é¿ã®ãŸã‚EPSG:3857ã§ç®—å‡ºâ†’4326ã¸ï¼‰"""
    if gdf is None or gdf.empty:
        return (35.681236, 139.767125)
    try:
        g3857 = gdf.to_crs(epsg=3857)
        cent = g3857.geometry.centroid
        cent = gpd.GeoSeries(cent, crs="EPSG:3857").to_crs(epsg=4326)
        return (float(cent.y.mean()), float(cent.x.mean()))
    except Exception:
        b = gdf.total_bounds
        return (float((b[1] + b[3]) / 2), float((b[0] + b[2]) / 2))




def format_label(v) -> str:
    """
    è¡¨ç¤ºç”¨ã®åœƒå ´åã‚’æ•´å½¢ï¼š
    - 408.0 â†’ 408
    - "0000484" â†’ "484"ï¼ˆæ•°å­—ã ã‘ã®æ–‡å­—åˆ—ã¯å…ˆé ­ã‚¼ãƒ­é™¤å»ï¼‰
    """
    if v is None:
        return ""


    # æ•°å€¤
    if isinstance(v, float):
        if pd.isna(v):
            return ""
        if v.is_integer():
            return str(int(v))
        s = str(v)
        return s.rstrip("0").rstrip(".")
    if isinstance(v, int):
        return str(v)


    # æ–‡å­—åˆ—
    s = str(v).strip()
    if not s:
        return ""


    # "408.0" ã¿ãŸã„ãªæ–‡å­—åˆ—
    if re.fullmatch(r"-?\d+\.0+", s):
        s = s.split(".")[0]


    # âœ… æ•°å­—ã ã‘ãªã‚‰å…ˆé ­ã‚¼ãƒ­ã‚’è½ã¨ã™ï¼ˆ"0000484"â†’"484"ï¼‰
    if re.fullmatch(r"\d+", s):
        s2 = s.lstrip("0")
        return s2 if s2 != "" else "0"


    return s




def gdf_to_shapefile_zip_bytes(gdf: gpd.GeoDataFrame, filename_prefix: str = "houjou_data") -> bytes:
    """Shapefile ZIP ã‚’ bytes ã§è¿”ã™"""
    with tempfile.TemporaryDirectory() as tmpdir:
        shp_path = f"{tmpdir}/{filename_prefix}.shp"
        gdf.to_file(shp_path, driver="ESRI Shapefile", encoding="UTF-8")


        bio = BytesIO()
        with zipfile.ZipFile(bio, "w", zipfile.ZIP_DEFLATED) as zf:
            for ext in [".shp", ".shx", ".dbf", ".prj", ".cpg"]:
                p = f"{tmpdir}/{filename_prefix}{ext}"
                try:
                    with open(p, "rb") as f:
                        zf.writestr(f"{filename_prefix}{ext}", f.read())
                except FileNotFoundError:
                    pass
        bio.seek(0)
        return bio.read()


def df_to_excel_bytes(df: pd.DataFrame, sheet_name: str = "matched") -> bytes:
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    bio.seek(0)
    return bio.read()




# =========================================================
# Sidebar (çŠ¶æ…‹ + ãƒªã‚»ãƒƒãƒˆã®ã¿)
# =========================================================
def sidebar_status(label: str, done: bool):
    st.sidebar.markdown(
        f"<div class='sidebar-item'>{html.escape(label)}ï¼š{'âœ…' if done else 'â€”'}</div>",
        unsafe_allow_html=True,
    )




st.sidebar.markdown("<div class='sidebar-title'>ç¾åœ¨ã®çŠ¶æ…‹</div>", unsafe_allow_html=True)


done_join = is_ready(st.session_state.joined) and (ADDRESS_COL_CANONICAL in st.session_state.joined.columns)
done_match = is_ready(st.session_state.matched)


sidebar_status("ç©ºé–“çµåˆ", done_join)
sidebar_status("ä½æ‰€ç…§åˆ", done_match)


if done_match:
    mm = st.session_state.matched
    ok = int((mm["match_status"] == "ä¸€è‡´").sum())
    tot = int(len(mm))
    st.sidebar.markdown("<div class='hr'></div>", unsafe_allow_html=True)
    st.sidebar.markdown("<div class='sidebar-title'>çµæœ</div>", unsafe_allow_html=True)
    st.sidebar.write(f"ä¸€è‡´: {ok:,} / {tot:,}ï¼ˆ{(ok/tot if tot else 0):.1%}ï¼‰")


st.sidebar.markdown("<div class='hr'></div>", unsafe_allow_html=True)
if st.sidebar.button("ğŸ” ã™ã¹ã¦ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
    reset_all()
    st.rerun()




# =========================================================
# Header
# =========================================================
st.title("ç­†ãƒãƒªã‚´ãƒ³Ã—ãƒ”ãƒ³ï¼šä½æ‰€ç…§åˆâ†’åœ°å›³â†’å‡ºåŠ›ï¼ˆ1ãƒšãƒ¼ã‚¸ï¼‰")
st.caption("å‡ºåŠ›Shapefileã®å±æ€§ã¯ FieldNameï¼ˆåœƒå ´åï¼‰ã®ã¿ã€‚è¡¨ç¤ºã®å…ˆé ­ã‚¼ãƒ­ï¼ˆ0000484â†’484ï¼‰ã‚‚è‡ªå‹•ä¿®æ­£ã—ã¾ã™ã€‚")


progress_steps = 0
progress_steps += 1 if done_join else 0
progress_steps += 1 if done_match else 0
st.progress(progress_steps / 2)


if st.session_state.upload_error:
    st.error(st.session_state.upload_error)


st.markdown("<div class='hr'></div>", unsafe_allow_html=True)




# =========================================================
# Step 1ï½œUploadï¼ˆçŠ¶æ…‹ã§ã‚«ãƒ¼ãƒ‰æ›´æ–°ï¼‰
# =========================================================
step1_slot = st.empty()
step_card_render(
    step1_slot,
    "Step 1ï½œGeoJSONã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    "ãƒ•ã‚¡ã‚¤ãƒ«åæ¡ä»¶ã«åˆã‚ãªã„å ´åˆã¯ã€ç†ç”±ã‚’è¡¨ç¤ºã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¬„ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚",
    done=False,
)


c1, c2 = st.columns(2, gap="large")


with c1:
    st.markdown("**ç­†ãƒãƒªã‚´ãƒ³ GeoJSONï¼ˆè¤‡æ•°å¯ï¼‰**")
    pori_files = st.file_uploader(
        "GeoJSON ã‚’é¸æŠ",
        type=["geojson"],
        accept_multiple_files=True,
        key=f"pori_files_{st.session_state.uploader_nonce}",
        help="ãƒ•ã‚¡ã‚¤ãƒ«åã«ã€Œç­†ãƒãƒªã‚´ãƒ³ã€ã‚’å«ã‚€å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚",
    )
    validate_filename_or_reset(pori_files, ["ç­†ãƒãƒªã‚´ãƒ³"], "ç­†ãƒãƒªã‚´ãƒ³ GeoJSON")


with c2:
    st.markdown("**ãƒ”ãƒ³ GeoJSONï¼ˆè¤‡æ•°å¯ï¼‰**")
    pin_files = st.file_uploader(
        "GeoJSON ã‚’é¸æŠ",
        type=["geojson"],
        accept_multiple_files=True,
        key=f"pin_files_{st.session_state.uploader_nonce}",
        help="ãƒ•ã‚¡ã‚¤ãƒ«åã«ã€Œè¾²åœ°ãƒ”ãƒ³ã€ã¾ãŸã¯ã€Œè¾²å ´ãƒ”ãƒ³ã€ã‚’å«ã‚€å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚",
    )
    validate_filename_or_reset(pin_files, ["è¾²åœ°ãƒ”ãƒ³", "è¾²å ´ãƒ”ãƒ³"], "ãƒ”ãƒ³ GeoJSON")


if st.session_state.upload_error and pori_files and pin_files:
    st.session_state.upload_error = None


done_step1 = bool(pori_files) and bool(pin_files) and (not st.session_state.upload_error)
step_card_render(
    step1_slot,
    "Step 1ï½œGeoJSONã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    "ãƒ•ã‚¡ã‚¤ãƒ«åæ¡ä»¶ã«åˆã‚ãªã„å ´åˆã¯ã€ç†ç”±ã‚’è¡¨ç¤ºã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¬„ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚",
    done=done_step1,
)


st.markdown("<div class='hr'></div>", unsafe_allow_html=True)




# =========================================================
# Step 2ï½œMerge + Spatial Joinï¼ˆä¸€æ‹¬ï¼‰
# =========================================================
step2_slot = st.empty()
step_card_render(
    step2_slot,
    "Step 2ï½œçµåˆ â†’ ç©ºé–“çµåˆ",
    f"CRSçµ±ä¸€â†’é‡è¤‡å‰Šé™¤â†’ç©ºé–“çµåˆã‚’ã¾ã¨ã‚ã¦å®Ÿè¡Œã—ã¾ã™ã€‚ä½æ‰€åˆ—ã¯ã€Œ{ADDRESS_COL_CANONICAL}ã€ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚",
    done=done_join,
)


can_run_step2 = bool(pori_files) and bool(pin_files)
run_clicked = st.button(
    "ğŸš€ Step 2 ã‚’å®Ÿè¡Œï¼ˆçµåˆâ†’ç©ºé–“çµåˆã¾ã§ä¸€æ‹¬ï¼‰",
    use_container_width=True,
    disabled=not can_run_step2,
)


if run_clicked:
    prog = st.progress(0)
    info = st.empty()
    try:
        info.text("1/3 èª­ã¿è¾¼ã¿ãƒ»çµåˆï¼ˆç­†ãƒãƒªã‚´ãƒ³ï¼‰â€¦")
        g_pori = dedupe_by_geometry(read_geojson(pori_files))
        prog.progress(0.33)


        info.text("2/3 èª­ã¿è¾¼ã¿ãƒ»çµåˆï¼ˆãƒ”ãƒ³ï¼‰â€¦")
        g_pin = dedupe_by_geometry(read_geojson(pin_files))
        prog.progress(0.66)


        st.session_state.merged_pori = g_pori
        st.session_state.merged_pins = g_pin
        st.session_state.joined = None
        st.session_state.matched = None


        info.text("3/3 ç©ºé–“çµåˆâ€¦")
        pori_sig = gdf_signature(st.session_state.merged_pori)
        pin_sig = gdf_signature(st.session_state.merged_pins)
        joined = sjoin_pori_pin(st.session_state.merged_pori, st.session_state.merged_pins, pori_sig, pin_sig)
        joined = ensure_address_column(joined)
        st.session_state.joined = joined


        prog.progress(1.0)
        if ADDRESS_COL_CANONICAL not in joined.columns:
            st.error(
                "ç©ºé–“çµåˆçµæœã« Address åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n\n"
                "å¯¾å¿œ: GeoJSONã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã«ã€ŒAddressã€ï¼ˆã¾ãŸã¯ Address_left / Address_rightï¼‰ãŒã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )
        else:
            st.success(f"âœ… Step2 å®Œäº†ï¼šç­†ãƒãƒªã‚´ãƒ³ {len(g_pori):,}ä»¶ / ãƒ”ãƒ³ {len(g_pin):,}ä»¶ï¼ˆä½æ‰€åˆ—ï¼šAddressï¼‰")
            st.rerun()


    except Exception as e:
        st.error(f"Step2ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\nã‚¨ãƒ©ãƒ¼: {e}")


if is_ready(st.session_state.merged_pori):
    with st.expander("çµ±åˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆç­†ãƒãƒªã‚´ãƒ³ãƒ»å…ˆé ­5ä»¶ï¼‰", expanded=False):
        st.table(slim_gdf_preview(st.session_state.merged_pori, n=5))


if is_ready(st.session_state.merged_pins):
    with st.expander("çµ±åˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ”ãƒ³ãƒ»å…ˆé ­5ä»¶ï¼‰", expanded=False):
        st.table(slim_gdf_preview(st.session_state.merged_pins, n=5))


if is_ready(st.session_state.joined):
    with st.expander("ç©ºé–“çµåˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­5ä»¶ï¼‰", expanded=False):
        st.table(slim_gdf_preview(st.session_state.joined, n=5))


st.markdown("<div class='hr'></div>", unsafe_allow_html=True)




# =========================================================
# Step 3ï½œExcel settingsï¼ˆçŠ¶æ…‹ã§ã‚«ãƒ¼ãƒ‰æ›´æ–°ï¼‰
# =========================================================
step3_slot = st.empty()
step_card_render(
    step3_slot,
    "Step 3ï½œExcelã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œãƒ»ä½æ‰€åˆ—ã‚’è¨­å®šï¼‰",
    "ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒåˆã£ã¦ã„ãã†ãªã‚‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒç·‘ã«ãªã‚Šã¾ã™ï¼ˆè‰²ï¼‹ãƒ†ã‚­ã‚¹ãƒˆã§åˆ¤å®šï¼‰ã€‚",
    done=False,
)


f_xlsx = st.file_uploader("åœƒå ´ç™»éŒ²ä»£è¡Œã‚·ãƒ¼ãƒˆï¼ˆExcelï¼‰", type=["xlsx", "xls"], key="xlsx")


st.session_state.strip_last_num = st.checkbox(
    "æœ«å°¾ã®æç•ªï¼ˆ-æ•°å­—ï¼‰ã‚’ç„¡è¦–ã—ã¦ç…§åˆï¼ˆ. / , / ã€ ã®æç•ªã¯å¸¸ã«å‰Šé™¤ï¼‰",
    value=bool(st.session_state.strip_last_num),
)


excel_ready = False
cand = []
pre = None


if f_xlsx:
    h = hash(f_xlsx.getvalue())
    if st.session_state.excel_hash != h:
        st.session_state.update({
            "sheet_name": None,
            "header_row": None,
            "excel_hash": h,
            "excel_addr_col": None,
            "field_name_col": None,
        })
        st.session_state.matched = None


    try:
        xls = pd.ExcelFile(f_xlsx)
        sheets = xls.sheet_names
    except Exception as e:
        st.error(f"Excelã®ã‚·ãƒ¼ãƒˆå–å¾—ã«å¤±æ•—: {e}")
        sheets = []


    if sheets:
        st.session_state.sheet_name = st.selectbox(
            "ã‚·ãƒ¼ãƒˆå",
            sheets,
            index=0 if st.session_state.sheet_name not in sheets else sheets.index(st.session_state.sheet_name),
        )


        pre = pd.read_excel(f_xlsx, sheet_name=st.session_state.sheet_name, header=None, nrows=40)
        st.caption("Excelãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®40è¡Œï¼‰")
        st.dataframe(pre, use_container_width=True, height=260)


        cand = suggest_header_rows(pre)
        default_header = cand[0] if cand else 0


        c1, c2 = st.columns([1, 1.6], gap="large")
        with c1:
            hdr = st.number_input(
                "ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆ0å§‹ã¾ã‚Šï¼‰",
                min_value=0, max_value=len(pre) - 1,
                value=st.session_state.header_row if st.session_state.header_row is not None else int(default_header),
                step=1,
            )
            if cand:
                pick = st.radio("å€™è£œï¼ˆãŠã™ã™ã‚ï¼‰", options=cand, index=0, format_func=lambda i: f"è¡Œ {i}")
                hdr = pick
            st.session_state.header_row = int(hdr)


        with c2:
            try:
                tmp = pd.read_excel(
                    f_xlsx,
                    sheet_name=st.session_state.sheet_name,
                    header=st.session_state.header_row,
                    nrows=10,
                    dtype=str,
                )
                good_hdr = is_good_header_choice(pre, st.session_state.header_row, list(tmp.columns), cand)


                st.caption("ãƒ˜ãƒƒãƒ€ãƒ¼é©ç”¨å¾Œãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(style_header_preview(tmp, good_hdr), use_container_width=True, height=220)
                st.write("åˆ¤å®š:", "âœ… ãƒ˜ãƒƒãƒ€ãƒ¼é©åˆã®å¯èƒ½æ€§ãŒé«˜ã„" if good_hdr else "âš ï¸ ãƒ˜ãƒƒãƒ€ãƒ¼ãŒåˆã£ã¦ã„ãªã„å¯èƒ½æ€§")


                excel_candidates = [c for c in tmp.columns if any(h in str(c) for h in ["ä½æ‰€åœ°ç•ª", "ä½æ‰€", "åœ°ç•ª"])]
                if st.session_state.excel_addr_col not in list(tmp.columns):
                    st.session_state.excel_addr_col = excel_candidates[0] if excel_candidates else list(tmp.columns)[0]


                st.session_state.excel_addr_col = st.selectbox(
                    "ä½æ‰€åˆ—ï¼ˆExcelå´ï¼‰",
                    options=list(tmp.columns),
                    index=list(tmp.columns).index(st.session_state.excel_addr_col)
                    if st.session_state.excel_addr_col in list(tmp.columns) else 0,
                )
                excel_ready = True


            except Exception as e:
                st.error(f"ãƒ˜ãƒƒãƒ€ãƒ¼é©ç”¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã‚¨ãƒ©ãƒ¼: {e}")


step_card_render(
    step3_slot,
    "Step 3ï½œExcelã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œãƒ»ä½æ‰€åˆ—ã‚’è¨­å®šï¼‰",
    "ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒåˆã£ã¦ã„ãã†ãªã‚‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒç·‘ã«ãªã‚Šã¾ã™ï¼ˆè‰²ï¼‹ãƒ†ã‚­ã‚¹ãƒˆã§åˆ¤å®šï¼‰ã€‚",
    done=excel_ready,
)


st.markdown("<div class='hr'></div>", unsafe_allow_html=True)




# =========================================================
# Step 4ï½œMatching
# =========================================================
done_match = is_ready(st.session_state.matched)
can_match = done_join and excel_ready and (st.session_state.header_row is not None) and (st.session_state.excel_addr_col is not None)


step4_slot = st.empty()
step_card_render(
    step4_slot,
    "Step 4ï½œä½æ‰€ç…§åˆï¼ˆExcel â†’ ç­†ãƒãƒªã‚´ãƒ³ï¼‰",
    f"ç©ºé–“çµåˆçµæœã®ã€Œ{ADDRESS_COL_CANONICAL}ã€ã‚’è¾æ›¸åŒ–ã—ã¦ã€Excelã®ä½æ‰€ã«ãƒãƒªã‚´ãƒ³ã‚’ä»˜ä¸ã—ã¾ã™ã€‚",
    done=done_match,
)


match_clicked = st.button("ğŸš€ ä½æ‰€ç…§åˆã‚’å®Ÿè¡Œ", use_container_width=True, disabled=not can_match)


if match_clicked:
    excel_addr = st.session_state.excel_addr_col
    with st.spinner("ç…§åˆä¸­â€¦"):
        df = pd.read_excel(
            f_xlsx,
            sheet_name=st.session_state.sheet_name,
            header=st.session_state.header_row,
            dtype=str,  # 408.0 / 0000484 ã‚’å£Šã•ãªã„ï¼ˆã“ã“ã§æ•´å½¢ã™ã‚‹ï¼‰
        )


        if excel_addr not in df.columns:
            st.error("é¸æŠã—ãŸä½æ‰€åˆ—ãŒExcelã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚ä½æ‰€åˆ—ã®é¸æŠã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
            st.stop()


        before = len(df)
        df = df.dropna(subset=[excel_addr]).copy()
        dropped = before - len(df)


        sig = gdf_signature(st.session_state.joined, ADDRESS_COL_CANONICAL)
        d1, d2 = build_addr_dict(
            st.session_state.joined,
            ADDRESS_COL_CANONICAL,
            sig,
            bool(st.session_state.strip_last_num),
        )


        matched = apply_match(df, excel_addr, d1, d2, bool(st.session_state.strip_last_num))
        st.session_state.matched = matched
        st.session_state.field_name_col = None


    if dropped > 0:
        st.info(f"ä½æ‰€ãŒç©ºã® {dropped:,} ä»¶ã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚")
    st.success("âœ… ä½æ‰€ç…§åˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    st.rerun()


st.markdown("<div class='hr'></div>", unsafe_allow_html=True)




# =========================================================
# Step 5ï½œMap + Export (Shapefile only, FieldName only)
# =========================================================
step5_slot = st.empty()
step_card_render(
    step5_slot,
    "Step 5ï½œåœ°å›³è¡¨ç¤º & å‡ºåŠ›ï¼ˆShapefileã®ã¿ï¼‰",
    "ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡ã«ã—ã¾ã™ã€‚Shapefileå±æ€§ã¯ FieldNameï¼ˆåœƒå ´åï¼‰ã ã‘ã‚’æ›¸ãè¾¼ã¿ã¾ã™ã€‚",
    done=False,
)


if is_ready(st.session_state.matched):
    m = st.session_state.matched
    ok = int((m["match_status"] == "ä¸€è‡´").sum())
    tot = int(len(m))
    ng = tot - ok
    rate = ok / tot if tot else 0


    k1, k2, k3 = st.columns(3)
    with k1:
        st.markdown(f"<div class='kpi'><b>ä¸€è‡´</b><br>{ok:,}</div>", unsafe_allow_html=True)
    with k2:
        st.markdown(f"<div class='kpi'><b>æœªä¸€è‡´</b><br>{ng:,}</div>", unsafe_allow_html=True)
    with k3:
        st.markdown(f"<div class='kpi'><b>ä¸€è‡´ç‡</b><br>{rate:.1%}</div>", unsafe_allow_html=True)


    st.markdown("### çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…¨ä»¶ãƒ»50ä»¶ã”ã¨ã«ãƒšãƒ¼ã‚¸åˆ†å‰²ï¼‰")
    filter_opt = st.selectbox("è¡¨ç¤ºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", ["å…¨ä»¶", "ä¸€è‡´ã®ã¿", "æœªä¸€è‡´ã®ã¿"], index=0)
    view = m
    if filter_opt == "ä¸€è‡´ã®ã¿":
        view = m[m["match_status"] == "ä¸€è‡´"]
    elif filter_opt == "æœªä¸€è‡´ã®ã¿":
        view = m[m["match_status"] != "ä¸€è‡´"]

    per_page = 50
    total = len(view)
    total_pages = max(1, (total + per_page - 1) // per_page)
    page = st.number_input("ãƒšãƒ¼ã‚¸", min_value=1, max_value=total_pages, value=1, step=1)
    start = (page - 1) * per_page
    end = start + per_page
    if total == 0:
        st.info("è©²å½“ã™ã‚‹è¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        view_page = view.head(0)
    else:
        st.caption(f"{total:,} ä»¶ä¸­ {start + 1:,} ã€œ {min(end, total):,} ä»¶ã‚’è¡¨ç¤ºï¼ˆ1ãƒšãƒ¼ã‚¸ {per_page} ä»¶ï¼‰")
        view_page = view.iloc[start:end]
    st.dataframe(view_page, use_container_width=True)
    csv_bytes = view.to_csv(index=False).encode("utf-8-sig")

    # Excel export (includes geometry_wkt for later re-import)
    try:
        xlsx_bytes = df_to_excel_bytes(view, sheet_name="matched")
        st.download_button(
            "Download matched results (Excel .xlsx)",
            data=xlsx_bytes,
            file_name="matched_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )
    except Exception as e:
        st.warning(f"Excel export failed (missing openpyxl?): {e}")

    st.download_button(
        "ğŸ“¥ çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå…¨è¡Œãƒ»CSVï¼‰",
        data=csv_bytes,
        file_name="matched_results.csv",
        mime="text/csv",
        use_container_width=True,
    )


    st.session_state.show_map = st.checkbox("ğŸ—ºï¸ åœ°å›³ã‚’è¡¨ç¤ºã™ã‚‹ï¼ˆé‡ã„å ´åˆã¯OFFï¼‰", value=bool(st.session_state.show_map))


    mg = m[m["match_status"] == "ä¸€è‡´"].copy()
    mg["geometry"] = mg["geometry_wkt"].apply(safe_load_wkt)
    mg = mg.dropna(subset=["geometry"])
    gdf = gpd.GeoDataFrame(mg, geometry="geometry", crs="EPSG:4326")


    if gdf.empty:
        st.warning("ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ãŒç„¡ã„ãŸã‚ã€åœ°å›³è¡¨ç¤ºãƒ»å‡ºåŠ›ã¯ã§ãã¾ã›ã‚“ã€‚")
        step_card_render(
            step5_slot,
            "Step 5ï½œåœ°å›³è¡¨ç¤º & å‡ºåŠ›ï¼ˆShapefileã®ã¿ï¼‰",
            "ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡ã«ã—ã¾ã™ã€‚Shapefileå±æ€§ã¯ FieldNameï¼ˆåœƒå ´åï¼‰ã ã‘ã‚’æ›¸ãè¾¼ã¿ã¾ã™ã€‚",
            done=False,
        )
    else:
        # åœƒå ´åã®å…ƒåˆ—ã‚’é¸æŠï¼ˆExcelåˆ—ã‹ã‚‰æŒ‡å®šå¯èƒ½ï¼‰
        label_candidates = ["åœƒå ´å", "FieldName", "field_name", "name", "åœƒå ´", "åœƒå ´ID", "FieldID"]
        fieldname_exclude = {"geometry", "geometry_wkt", "match_status"}
        fieldname_options = [c for c in gdf.columns if c not in fieldname_exclude]
        preferred = [c for c in label_candidates if c in fieldname_options]
        default_field = (
            st.session_state.field_name_col
            if st.session_state.field_name_col in fieldname_options
            else (preferred[0] if preferred else (fieldname_options[0] if fieldname_options else None))
        )

        if fieldname_options:
            st.session_state.field_name_col = st.selectbox(
                "ã‚·ã‚§ãƒ¼ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã™åœƒå ´ååˆ—ï¼ˆExcelåˆ—ï¼‰",
                options=fieldname_options,
                index=fieldname_options.index(default_field) if default_field in fieldname_options else 0,
                help="Shapefile ã® FieldName ã«ä½¿ã†åˆ—ã‚’é¸æŠã—ã¾ã™ã€‚Excelå´ã®åˆ—ã‚’ç›´æ¥æŒ‡å®šã§ãã¾ã™ã€‚",
            )
            preview_col = st.session_state.field_name_col
            st.caption("åœƒå ´åãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­15ä»¶ï¼‰")
            st.table(pd.DataFrame({preview_col: gdf[preview_col].head(15).apply(format_label)}))
        else:
            st.session_state.field_name_col = None
            st.warning("åœƒå ´åã«ä½¿ãˆã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Excelã«åœƒå ´åã®åˆ—ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

        src_name_col = st.session_state.field_name_col


        # åœ°å›³
        if st.session_state.show_map:
            lat, lon = safe_centroid_lonlat(gdf)
            mp = folium.Map(location=[lat, lon], zoom_start=14)


            gdf_map = gdf.drop(columns=["geometry_wkt"], errors="ignore")


            # propertiesãŒShapelyã‚’å«ã¾ãªã„ã‚ˆã†æ–‡å­—åˆ—åŒ–ï¼ˆå®‰å…¨ï¼‰
            for c in [c for c in gdf_map.columns if c != "geometry"]:
                gdf_map[c] = gdf_map[c].astype(str).fillna("")


            excel_addr = st.session_state.excel_addr_col
            tooltip_fields = []
            if src_name_col and src_name_col in gdf_map.columns:
                tooltip_fields.append(src_name_col)
            if excel_addr in gdf_map.columns:
                tooltip_fields.append(excel_addr)


            folium.GeoJson(
                gdf_map.__geo_interface__,
                tooltip=folium.features.GeoJsonTooltip(fields=tooltip_fields) if tooltip_fields else None,
            ).add_to(mp)


            # ãƒ©ãƒ™ãƒ«ï¼ˆå¤§é‡ä»¶æ•°ã¯äº‹æ•…é˜²æ­¢ï¼‰
            if src_name_col:
                if len(gdf) > 1000:
                    st.info("ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ãŒå¤šã„ãŸã‚ã€ãƒ©ãƒ™ãƒ«è¡¨ç¤ºã¯ç„¡åŠ¹åŒ–ã—ã¦ã„ã¾ã™ï¼ˆæ€§èƒ½ä¿è­·ï¼‰ã€‚")
                else:
                    default_on = len(gdf) <= 200
                    show_labels = st.checkbox(f"ğŸ·ï¸ åœƒå ´åãƒ©ãƒ™ãƒ«ã‚’è¡¨ç¤ºï¼ˆå…ƒåˆ—: {src_name_col}ï¼‰", value=default_on)
                    if show_labels:
                        for _, row in gdf.iterrows():
                            label = format_label(row.get(src_name_col, ""))
                            if not label:
                                continue
                            p = row.geometry.representative_point()
                            folium.Marker(
                                location=[p.y, p.x],
                                icon=folium.DivIcon(
                                    html=(
                                        f"<div style="
                                        f"'font-size:{LABEL_FONT_SIZE}px;"
                                        f"font-weight:800;"
                                        f"color:#111;"
                                        f"background:rgba(255,255,255,0.75);"
                                        f"padding:1px 4px;"
                                        f"border-radius:6px;"
                                        f"border:1px solid rgba(0,0,0,0.15);"
                                        f"white-space:nowrap;'>"
                                        f"{html.escape(label)}"
                                        f"</div>"
                                    )
                                ),
                            ).add_to(mp)


            minx, miny, maxx, maxy = gdf.total_bounds
            mp.fit_bounds([[miny, minx], [maxy, maxx]])
            folium_static(mp, width=1100, height=650)


        # ------------- å‡ºåŠ›ï¼ˆFieldNameã®ã¿ï¼‰-------------
        st.markdown("### å‡ºåŠ›ï¼ˆShapefile ZIPï¼‰")
        out_prefix = st.text_input("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ãªã—ï¼‰", value="houjou_data")


        if src_name_col and src_name_col in gdf.columns:
            names = gdf[src_name_col].apply(format_label).fillna("").astype(str)
        else:
            names = pd.Series([""] * len(gdf))


        # DBFã¯1ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æœ€å¤§254bytesç›®å®‰ â†’ å¿µã®ãŸã‚çŸ­ã‚ã«åˆ‡ã‚‹
        names = names.str.slice(0, 200)


        gdf_export = gpd.GeoDataFrame(
            {"FieldName": names, "geometry": gdf.geometry},
            geometry="geometry",
            crs="EPSG:4326",
        )


        shp_bytes = gdf_to_shapefile_zip_bytes(gdf_export, filename_prefix=out_prefix)


        st.download_button(
            "ğŸ“¥ Shapefileï¼ˆZIPï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=shp_bytes,
            file_name=f"{out_prefix}.zip",
            mime="application/zip",
            use_container_width=True,
        )


        st.caption("â€» Shapefileã®å±æ€§ã¯ FieldNameï¼ˆåœƒå ´åï¼‰ã ã‘ã§ã™ï¼ˆå…ˆé ­ã‚¼ãƒ­ã¯è‡ªå‹•é™¤å»ï¼‰ã€‚")


        # Step5 å®Œäº†ï¼ˆä¸€è‡´ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹æ™‚ç‚¹ã§å®Œäº†æ‰±ã„ï¼‰
        step_card_render(
            step5_slot,
            "Step 5ï½œåœ°å›³è¡¨ç¤º & å‡ºåŠ›ï¼ˆShapefileã®ã¿ï¼‰",
            "ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡ã«ã—ã¾ã™ã€‚Shapefileå±æ€§ã¯ FieldNameï¼ˆåœƒå ´åï¼‰ã ã‘ã‚’æ›¸ãè¾¼ã¿ã¾ã™ã€‚",
            done=True,
        )
else:
    st.info("Step 4 ã®ã€Œä½æ‰€ç…§åˆã‚’å®Ÿè¡Œã€ã‚’æŠ¼ã™ã¨ã€ã“ã“ã«åœ°å›³ã¨ Shapefile å‡ºåŠ›ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")


st.markdown("<div class='hr'></div>", unsafe_allow_html=True)


# =========================================================
# Step 6ï½œRe-import matched Excel -> Shapefile
# =========================================================
step6_slot = st.empty()
step6_done = bool(st.session_state.get("step6_done", False))
step_card_render(
    step6_slot,
    "Step 6ï½œç…§åˆæ¸ˆã¿Excel â†’ Shapefileï¼ˆå†ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰",
    "ä½æ‰€ç…§åˆæ¸ˆã¿Excelï¼ˆgeometry_wktåˆ—ã‚ã‚Šï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ã„ããªã‚ŠShapefile ZIPã‚’ä½œæˆã—ã¾ã™ã€‚",
    done=step6_done,
)

st.caption("â€» Step 6 ã¯ Step 1ã€œ5 ã‚’å®Ÿè¡Œã—ãªãã¦ã‚‚ä½¿ãˆã¾ã™ã€‚")
step6_xlsx = st.file_uploader("ç…§åˆæ¸ˆã¿Excelï¼ˆ.xlsxï¼‰", type=["xlsx"], key="step6_reimport_xlsx")

if step6_xlsx is not None:
    try:
        step6_df = pd.read_excel(step6_xlsx, dtype=str)
    except Exception as e:
        st.session_state.step6_done = False
        st.error(f"Excelã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆopenpyxlæœªå°å…¥ãªã©ï¼‰: {e}")
        step6_df = None

    if step6_df is not None:
        if step6_df.empty:
            st.session_state.step6_done = False
            st.warning("ExcelãŒç©ºã§ã™ã€‚")
        else:
            if "geometry_wkt" in step6_df.columns:
                step6_geom_col = "geometry_wkt"
            else:
                st.warning("`geometry_wkt` åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚WKTãŒå…¥ã£ã¦ã„ã‚‹åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                step6_geom_col = st.selectbox("WKTã‚¸ã‚ªãƒ¡ãƒˆãƒªåˆ—", options=list(step6_df.columns), key="step6_geom_col")

            tmp6 = step6_df.copy()
            tmp6["geometry"] = tmp6[step6_geom_col].apply(safe_load_wkt)
            tmp6 = tmp6.dropna(subset=["geometry"])
            gdf6 = gpd.GeoDataFrame(tmp6, geometry="geometry", crs="EPSG:4326")

            if gdf6.empty:
                st.session_state.step6_done = False
                st.warning("æœ‰åŠ¹ãªWKTã‚¸ã‚ªãƒ¡ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Shapefileã‚’ä½œæˆã§ãã¾ã›ã‚“ã€‚")
            else:
                st.session_state.step6_done = True
                step_card_render(
                    step6_slot,
                    "Step 6ï½œç…§åˆæ¸ˆã¿Excel â†’ Shapefileï¼ˆå†ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰",
                    "ä½æ‰€ç…§åˆæ¸ˆã¿Excelï¼ˆgeometry_wktåˆ—ã‚ã‚Šï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ã„ããªã‚ŠShapefile ZIPã‚’ä½œæˆã—ã¾ã™ã€‚",
                    done=True,
                )

                st.caption("å†ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœï¼ˆå…ˆé ­5ä»¶ï¼‰")
                st.table(slim_gdf_preview(gdf6, n=5))

                exclude_cols6 = {"geometry", step6_geom_col, "match_status"}
                name_options6 = [c for c in gdf6.columns if c not in exclude_cols6]
                name_col6 = (
                    st.selectbox("FieldNameã«ä½¿ã†åˆ—ï¼ˆä»»æ„ï¼‰", options=name_options6, index=0, key="step6_name_col")
                    if name_options6
                    else None
                )

                out_prefix6 = st.text_input("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ãªã—ï¼‰", value="houjou_data_step6", key="step6_out_prefix")

                if name_col6 and name_col6 in gdf6.columns:
                    names6 = gdf6[name_col6].apply(format_label).fillna("").astype(str).str.slice(0, 200)
                else:
                    names6 = pd.Series([""] * len(gdf6))

                st.markdown("### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆåœƒå ´å Ã— ãƒãƒªã‚´ãƒ³ï¼‰")
                preview_rows6 = min(20, len(gdf6))
                preview_df6 = pd.DataFrame(
                    {
                        "FieldName": names6.head(preview_rows6).astype(str).fillna(""),
                        "GeometryType": gdf6.geometry.head(preview_rows6).apply(
                            lambda g: g.geom_type if isinstance(g, BaseGeometry) else ""
                        ),
                    }
                )
                st.table(preview_df6)

                show_step6_map = st.checkbox(
                    "åœ°å›³ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤ºï¼ˆä»¶æ•°ãŒå¤šã„å ´åˆã¯OFFï¼‰",
                    value=len(gdf6) <= 200,
                    key="step6_show_map",
                )
                if show_step6_map:
                    gdf6_map = gdf6.copy()
                    gdf6_map["FieldName"] = names6
                    for c in [c for c in gdf6_map.columns if c != "geometry"]:
                        gdf6_map[c] = gdf6_map[c].astype(str).fillna("")

                    max_map_rows = 1000
                    if len(gdf6_map) > max_map_rows:
                        st.info(f"ä»¶æ•°ãŒå¤šã„ãŸã‚ã€åœ°å›³è¡¨ç¤ºã¯å…ˆé ­ {max_map_rows:,} ä»¶ã«åˆ¶é™ã—ã¾ã™ã€‚")
                        gdf6_map = gdf6_map.head(max_map_rows)

                    lat6, lon6 = safe_centroid_lonlat(gdf6_map)
                    mp6 = folium.Map(location=[lat6, lon6], zoom_start=14)
                    folium.GeoJson(
                        gdf6_map.__geo_interface__,
                        tooltip=folium.features.GeoJsonTooltip(fields=["FieldName"]),
                    ).add_to(mp6)
                    minx, miny, maxx, maxy = gdf6_map.total_bounds
                    mp6.fit_bounds([[miny, minx], [maxy, maxx]])
                    folium_static(mp6, width=1100, height=650)

                gdf6_export = gpd.GeoDataFrame(
                    {"FieldName": names6, "geometry": gdf6.geometry},
                    geometry="geometry",
                    crs="EPSG:4326",
                )
                shp6 = gdf_to_shapefile_zip_bytes(gdf6_export, filename_prefix=out_prefix6)
                st.download_button(
                    "ğŸ“¥ Shapefile ZIP ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=shp6,
                    file_name=f"{out_prefix6}.zip",
                    mime="application/zip",
                    use_container_width=True,
                )

