import streamlit as st
st.set_page_config(page_title="xarvio BBCH Viewer", layout="wide")
import plotly.graph_objects as go
import tempfile
import base64
import requests
import urllib.parse
import pandas as pd
import json
from shapely.geometry import shape, MultiPolygon, Polygon
from geopy.geocoders import Nominatim
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
from xml.etree.ElementTree import Element, SubElement, tostring
import xml.dom.minidom
from datetime import datetime, timezone, timedelta
import plotly.express as px
import time 
from geopy.distance import geodesic

# ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ç”¨
date_color_map = {}


def extract_lat_lon(coord_str):
    try:
        lon, lat = map(float, coord_str.split(","))
        return lat, lon
    except:
        return None, None

def create_efficient_route(bbch_df, bbch_code):
    filtered_df = bbch_df[bbch_df["BBCHã‚³ãƒ¼ãƒ‰"] == bbch_code].dropna(subset=["ä¸­å¿ƒåº§æ¨™"])
    
    # åœƒå ´ã”ã¨ã®åº§æ¨™ã‚’æŠ½å‡º
    points = []
    for _, row in filtered_df.iterrows():
        lat, lon = extract_lat_lon(row["ä¸­å¿ƒåº§æ¨™"])
        if lat and lon:
            points.append({
                "name": row["åœƒå ´å"],
                "lat": lat,
                "lon": lon
            })

    if not points:
        return None, []

    # Greedyæ³•ï¼šç¾åœ¨ä½ç½®ã«æœ€ã‚‚è¿‘ã„é †ã«å·¡å›
    start = points[0]
    route = [start]
    remaining = points[1:]

    while remaining:
        last = route[-1]
        next_point = min(remaining, key=lambda p: geodesic((last["lat"], last["lon"]), (p["lat"], p["lon"])).km)
        route.append(next_point)
        remaining.remove(next_point)

    return route[0], route  # æœ€åˆã®åœƒå ´, å·¡å›é †

def generate_google_maps_route(route):
    if len(route) < 2:
        return None
    max_waypoints = 23
    trimmed_route = route[:max_waypoints]

    origin = "My+Location"
    destination = "My+Location"
    waypoints = "|".join([f'{pt["lat"]},{pt["lon"]}' for pt in trimmed_route])

    return f"https://www.google.com/maps/dir/?api=1&origin={origin}&destination={destination}&waypoints={waypoints}"


def plot_bbch_stacked_bar(df):
    """BBCHé–‹å§‹æ—¥ã®ç©ç«‹æ£’ã‚°ãƒ©ãƒ•ï¼ˆxè»¸ã¯ã‚«ãƒ†ã‚´ãƒªå‹ã§æ—¥åˆ¥ã«æ˜ç¤ºçš„ã«åˆ†é›¢ï¼‰"""
    required_columns = ["BBCHé–‹å§‹æ—¥", "å¸‚åŒºç”ºæ‘", "BBCHã‚¹ãƒ†ãƒ¼ã‚¸", "BBCHã‚³ãƒ¼ãƒ‰", "ä½œç‰©", "å“ç¨®", "åœƒå ´å", "è¾²å ´å"]
    if not all(col in df.columns for col in required_columns):
        st.warning("å¿…è¦ãªã‚«ãƒ©ãƒ ï¼ˆBBCHé–‹å§‹æ—¥ã€BBCHã‚¹ãƒ†ãƒ¼ã‚¸ã€ä½œç‰©ãªã©ï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return

    # â‘  æ—¥ä»˜ã‚’UTCâ†’æ—¥æœ¬æ™‚é–“ã¸å¤‰æ›ã—ã¦æ—¥ä»˜æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆã‚«ãƒ†ã‚´ãƒªè»¸å¯¾å¿œï¼‰
    df["BBCHé–‹å§‹æ—¥"] = pd.to_datetime(df["BBCHé–‹å§‹æ—¥"], utc=True, errors='coerce')
    df["BBCHé–‹å§‹æ—¥"] = df["BBCHé–‹å§‹æ—¥"].dt.tz_convert("Asia/Tokyo").dt.date.astype(str)


    # â‘¢ è‰²åˆ†ã‘æ–¹æ³•ã‚’é¸æŠ
    color_by_option = st.radio(
        "è‰²åˆ†ã‘ã®åŸºæº–ã‚’é¸æŠ",
        ["åœƒå ´å", "ä½œç‰©", "å“ç¨®","å¸‚åŒºç”ºæ‘" ],
        horizontal=True
    )

        
    # âœ… ğŸŒ¾ è¡¨ç¤ºã™ã‚‹ä½œç‰©ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
    crop_options = sorted(df["ä½œç‰©"].dropna().unique(), reverse=True)
    selected_crop = st.radio("ğŸŒ¾ è¡¨ç¤ºã™ã‚‹ä½œç‰©ã‚’é¸æŠ", options=crop_options, horizontal=True)
    unique_stages = df[df["ä½œç‰©"] == selected_crop][["BBCHã‚³ãƒ¼ãƒ‰", "BBCHåç§°"]].dropna().drop_duplicates()

    # âœ… BBCHã‚¹ãƒ†ãƒ¼ã‚¸ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼ˆå…ƒã® df_filtered ã§å–å¾—ï¼‰
    unique_stages["BBCHã‚³ãƒ¼ãƒ‰ã‚½ãƒ¼ãƒˆ"] = unique_stages["BBCHã‚³ãƒ¼ãƒ‰"].astype(int)
    unique_stages = unique_stages.sort_values("BBCHã‚³ãƒ¼ãƒ‰ã‚½ãƒ¼ãƒˆ")

    # è¡¨ç¤ºç”¨ã«æ•´å½¢ï¼ˆä¾‹: "13 (3è‘‰æœŸ)"ï¼‰
    unique_stages["ãƒ©ãƒ™ãƒ«"] = unique_stages["BBCHã‚³ãƒ¼ãƒ‰"].astype(str) + " (" + unique_stages["BBCHåç§°"] + ")"

    # ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã«æ¸¡ã™
    selected_stage = st.radio("è¡¨ç¤ºã™ã‚‹BBCHã‚¹ãƒ†ãƒ¼ã‚¸ã‚’é¸ã‚“ã§ãã ã•ã„", unique_stages["ãƒ©ãƒ™ãƒ«"].tolist(), horizontal=True)


    filtered_df = df[(df["ä½œç‰©"] == selected_crop) & (df["BBCHã‚¹ãƒ†ãƒ¼ã‚¸"] == selected_stage)].copy()

    # åœƒå ´åï¼ˆè¾²å ´åï¼‰ã¨ã„ã†ãƒ©ãƒ™ãƒ«åˆ—ã‚’è¿½åŠ 
    filtered_df["åœƒå ´ãƒ©ãƒ™ãƒ«"] = filtered_df["åœƒå ´å"] + "ï¼ˆ" + filtered_df["è¾²å ´å"] + "ï¼‰"



    if color_by_option == "å¸‚åŒºç”ºæ‘":
        group_cols = ["BBCHé–‹å§‹æ—¥", "å¸‚åŒºç”ºæ‘"]
        color_column = "å¸‚åŒºç”ºæ‘"
    elif color_by_option == "ä½œç‰©":
        group_cols = ["BBCHé–‹å§‹æ—¥", "ä½œç‰©"]
        color_column = "ä½œç‰©"

    elif color_by_option == "å“ç¨®":
        group_cols = ["BBCHé–‹å§‹æ—¥", "å“ç¨®"]
        color_column = "å“ç¨®"

    elif color_by_option == "åœƒå ´å":
        group_cols = ["BBCHé–‹å§‹æ—¥", "åœƒå ´ãƒ©ãƒ™ãƒ«"]  # â† å¤‰æ›´
        color_column = "åœƒå ´ãƒ©ãƒ™ãƒ«"               # â† å¤‰æ›´

        
    # â‘£ é›†è¨ˆ
    date_counts = filtered_df.groupby(group_cols).size().reset_index(name="ã‚«ã‚¦ãƒ³ãƒˆ")
    
    # âœ… æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆã—ã¦ã‚«ãƒ†ã‚´ãƒªå‹ã«å¤‰æ›ï¼ˆé †ç•ªã‚’å›ºå®šï¼‰
    sorted_dates = sorted(date_counts["BBCHé–‹å§‹æ—¥"].unique())
    date_counts["BBCHé–‹å§‹æ—¥"] = pd.Categorical(
        date_counts["BBCHé–‹å§‹æ—¥"],
        categories=sorted_dates,
        ordered=True
    )


    # â‘¤ ã‚°ãƒ©ãƒ•ä½œæˆ
    fig = px.bar(
        date_counts,
        x="BBCHé–‹å§‹æ—¥",
        y="ã‚«ã‚¦ãƒ³ãƒˆ",
        color=color_column,
        title=f"BBCHã‚¹ãƒ†ãƒ¼ã‚¸ {selected_stage} ã®é–‹å§‹æ—¥åˆ†å¸ƒ",
        hover_data={"BBCHé–‹å§‹æ—¥": True},
        labels={
            "BBCHé–‹å§‹æ—¥": "BBCHé–‹å§‹æ—¥",
            "ã‚«ã‚¦ãƒ³ãƒˆ": "åœƒå ´æ•°",
            "å¸‚åŒºç”ºæ‘": "å¸‚åŒºç”ºæ‘",
            "å¸‚åŒºç”ºæ‘_BBCH": "å¸‚åŒºç”ºæ‘ + BBCHã‚¹ãƒ†ãƒ¼ã‚¸",
        },
    )

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ï¼ˆã‚«ãƒ†ã‚´ãƒªè»¸ã¨ã—ã¦xã‚’æ‰±ã†ï¼ï¼‰
    fig.update_layout(
        xaxis_title="BBCHé–‹å§‹æ—¥",
        yaxis_title="åœƒå ´æ•°",
        barmode="stack",
        bargap=0.1
    )
    fig.update_xaxes(
    type="category",  # â† æ˜ç¤ºçš„ã«ã‚«ãƒ†ã‚´ãƒªæ‰±ã„
    categoryorder="array",
    categoryarray=sorted_dates,  # â† ä¸¦ã³é †æŒ‡å®š
    tickangle=45
    )

    # ã‚°ãƒ©ãƒ•è¡¨ç¤º
    st.plotly_chart(fig, use_container_width=True)

    st.write("ğŸ” ã‚°ãƒ©ãƒ•ã®ãƒ‡ãƒ¼ã‚¿", filtered_df)
    
@st.cache_data(show_spinner=False)
def reverse_geocode(lat, lon):
    #st.write(f"ğŸ“ reverse_geocode called: {lat}, {lon}")
    geolocator = Nominatim(user_agent="xarvio-app")
    location = geolocator.reverse((lat, lon), language="ja")
    return location.raw.get("address", {})

def show_debug_info():
    st.markdown("## ğŸ§ª ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
    st.write(f"ğŸ” GraphQL APIå‘¼ã³å‡ºã—å›æ•°: {st.session_state['graphql_api_call_count']} å›")
    st.write(f"ğŸ§  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {st.session_state['reverse_geocode_cache_hits']} å›")
    st.write(f"âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹: {st.session_state['reverse_geocode_cache_misses']} å›")



    
def get_color_for_date(date):
    if date not in date_color_map:
        color = "hsl({}, 70%, 60%)".format((len(date_color_map) * 40) % 360)
        date_color_map[date] = color
    return date_color_map[date]

def get_user_inputs(field_data):
    """åœ°å›³ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»BBCHãƒ»ã‚¿ã‚¤ãƒˆãƒ«ã®é¸æŠã‚’UIã§å–å¾—"""
    map_style_label_to_value = {
        "æ¨™æº–": "open-street-map",
        "ã‚·ãƒ³ãƒ—ãƒ«": "carto-positron"
    }

    with st.expander("âš™ï¸ è¡¨ç¤ºè¨­å®š", expanded=False):
        title_prefix = st.text_input("åœƒå ´ãƒãƒƒãƒ—ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä»»æ„ï¼‰", placeholder="ä¾‹: æ–°æ½Ÿè¥¿éƒ¨")

        selected_style_label = st.radio("åœ°å›³ã‚¹ã‚¿ã‚¤ãƒ«", options=list(map_style_label_to_value.keys()), horizontal=True)
        selected_map_style = map_style_label_to_value[selected_style_label]


        # æ–‡å­—åˆ— â†’ æ•°å€¤ â†’ ã‚½ãƒ¼ãƒˆ â†’ æ–‡å­—åˆ—ã«æˆ»ã™
        all_bbch = sorted(
            {int(f["BBCHã‚³ãƒ¼ãƒ‰"]) for f in field_data if "BBCHã‚³ãƒ¼ãƒ‰" in f and str(f["BBCHã‚³ãƒ¼ãƒ‰"]).isdigit()}
        )
        all_bbch = [str(code) for code in all_bbch]

        selected_bbch = st.radio("BBCHã‚¹ãƒ†ãƒ¼ã‚¸ã‚’é¸æŠ", options=all_bbch, index=0, horizontal=True)

        if selected_bbch:
            st.caption(f"ğŸ“˜ {selected_bbch}ï¼š{bbch_df[bbch_df['BBCHã‚³ãƒ¼ãƒ‰'] == selected_bbch]['BBCHåç§°'].iloc[0]}")
    
        # ãƒ©ãƒ™ãƒ«è¡¨ç¤ºé …ç›®ã®é¸æŠ
        label_options = {
            "åœƒå ´å": "name",
            "å“ç¨®": "variety",
            "ä½œä»˜æ—¥": "date"
        }
        selected_label_key = st.radio("åœƒå ´ãƒ©ãƒ™ãƒ«ã«è¡¨ç¤ºã™ã‚‹æƒ…å ±", list(label_options.keys()), horizontal=True)
        selected_label = label_options[selected_label_key]

    return selected_map_style, selected_bbch, title_prefix, selected_label

def generate_map_title(prefix, bbch):
    if prefix.strip():
        return f"ã€{prefix.strip()}ã€‘åœƒå ´ãƒãƒƒãƒ— BBCH{bbch}"
    else:
        return f"åœƒå ´ãƒãƒƒãƒ— BBCH{bbch}"

def create_field_map(field_data, selected_bbch, map_style, map_title, label_key, center_override=None, zoom_override=None):
    """Plotlyåœ°å›³ã®ç”Ÿæˆ"""
    filtered_data = [f for f in field_data if f.get("BBCHã‚³ãƒ¼ãƒ‰") == selected_bbch]
    fig = go.Figure()

    legend_dates_added = set()

    for field in filtered_data:
        poly = Polygon(field["coords"])
        lons, lats = poly.exterior.xy
        date = field["date"]
        color = get_color_for_date(date)

        if date not in legend_dates_added:
            fig.add_trace(go.Scattermapbox(
                lat=[None], lon=[None],
                mode="markers",
                marker=dict(size=10, color=color),
                name=date,
                legendgroup=date,
                showlegend=True
            ))
            legend_dates_added.add(date)

        fig.add_trace(go.Scattermapbox(
            lat=list(lats), lon=list(lons),
            mode="lines", fill="toself",
            name=field["name"],
            line=dict(width=2, color="grey"),  
            fillcolor=color,
            hoverinfo="skip", showlegend=False,
            legendgroup=date
        ))

        centroid = poly.centroid
        lat, lon = centroid.y, centroid.x
        # ğŸ”´ èµ¤ã„ãƒ”ãƒ³ãƒãƒ¼ã‚¯ã‚’è¿½åŠ ï¼ˆåœƒå ´ã®ä¸­å¿ƒã«ï¼‰
        fig.add_trace(go.Scattermapbox(
            lat=[lat], lon=[lon],
            mode="markers",
            marker=dict(size=10, color="red", symbol="circle"),  # â† ã“ã“ãŒç›®ç«‹ã¤ãƒã‚¤ãƒ³ãƒˆ
            name=field["name"],
            hoverinfo="skip",
            showlegend=False
        ))

        gmap_url = f"https://www.google.com/maps/dir/?api=1&destination={lat},{lon}"
        hover_html = (
            f"<b>{field['name']}</b><br>"
            f"è¾²å ´å: {field.get('è¾²å ´å', 'ä¸æ˜')}<br>"
            f"ä½œç‰©: {field.get('ä½œç‰©', 'ä¸æ˜')}<br>"
            f"å“ç¨®: {field['variety']}<br>"
            f"ä½œä»˜æ–¹æ³•: {field.get('ä½œä»˜æ–¹æ³•', '')}<br>"
            f"<a href='{gmap_url}' target='_blank'>ğŸ“Googleãƒãƒƒãƒ—</a><br>"
            f"é¢ç©: {field.get('é¢ç© (a)', '')} a<br>"
            f"ä½œä»˜æ—¥: {field['date']}<br>"
            f"BBCH: {field.get('BBCHã‚³ãƒ¼ãƒ‰', '')}ï¼ˆ{field.get('BBCHåç§°', '')}ï¼‰<br>"
            
        )

        fig.add_trace(go.Scattermapbox(
            lat=[lat],
            lon=[lon],
            mode="markers",
            marker=dict(
                size=30,                # â† å¤§ããã™ã‚‹ã“ã¨ã§ hover ã—ã‚„ã™ããªã‚‹
                color="rgba(0,0,0,0)"   # â† å®Œå…¨ã«é€æ˜
            ),
            hoverinfo="text",
            hovertext=hover_html,
            showlegend=False
        ))
        label_text = str(field.get(label_key, ""))
        fig.add_trace(go.Scattermapbox(
            lat=[lat], lon=[lon],
            mode="text",
            marker=dict(size=3, color="rgba(255,255,255,0.1)"),
            text=[label_text],
            textposition="middle center",
            textfont=dict(size=14, color="black"),
            hoverinfo="skip",
            showlegend=False
        ))
        

    # åœƒå ´ã®é‡å¿ƒï¼ˆä¸­å¿ƒï¼‰ã‚’å…ƒã«åœ°å›³ã®ä¸­å¿ƒåº§æ¨™ã‚’å‹•çš„ã«è¨­å®š
    centroids = []
    for field in filtered_data:
        try:
            poly = Polygon(field["coords"])
            centroids.append(poly.centroid)
        except:
            continue

    if centroids:
        lats = [pt.y for pt in centroids]
        lons = [pt.x for pt in centroids]

        min_lat, max_lat = min(lats), max(lats)
        min_lon, max_lon = min(lons), max(lons)
        avg_lat = sum(lats) / len(lats)
        avg_lon = sum(lons) / len(lons)

        # åœ°ç†çš„ãªåºƒãŒã‚Šã®è·é›¢ã‚’è¨ˆç®—ï¼ˆç·¯åº¦ãƒ»çµŒåº¦ã®å·®ã‹ã‚‰ç°¡æ˜“æ¨å®šï¼‰
        lat_range = max_lat - min_lat
        lon_range = max_lon - min_lon
        max_range = max(lat_range, lon_range)

        # åœ°å›³ã‚ºãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã®ç›®å®‰ã‚’æ±ºå®šï¼ˆæ—¥æœ¬å…¨ä½“ãªã‚‰zoom=5ã€ç‹­ã„ç¯„å›²ãªã‚‰zoom=10ä»¥ä¸Šï¼‰
        if max_range < 0.01:
            map_zoom = 15
        elif max_range < 0.05:
            map_zoom = 13
        elif max_range < 0.1:
            map_zoom = 11
        elif max_range < 0.5:
            map_zoom = 9
        elif max_range < 1.5:
            map_zoom = 7
        else:
            map_zoom = 5

        map_center = {"lat": avg_lat, "lon": avg_lon}
    else:
        map_center = {"lat": 36.2048, "lon": 138.2529}
        map_zoom = 5

    # åœ°å›³ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã«åæ˜ 
    fig.update_layout(
        title={"text": map_title, "x": 0.5, "xanchor": "center", "font": dict(size=20, color="black")},
        mapbox_style=map_style,
        mapbox_zoom=zoom_override if zoom_override else map_zoom,
        mapbox_center=center_override if center_override else map_center,
        height=800, 
        margin={"r": 0, "t": 60, "l": 0, "b": 0},
        legend=dict(orientation="v", x=1.02, y=1.0, xanchor="left", yanchor="top", bordercolor="gray", borderwidth=1)
    )

    return fig

def download_map_html(fig):
    """åœ°å›³ã‚’HTMLã¨ã—ã¦ä¿å­˜ã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯è¡¨ç¤º"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as tmpfile:
        fig.write_html(
            tmpfile.name,
            include_plotlyjs="cdn",
            
            config={
                    "scrollZoom": True,
                    "displayModeBar": True,  # ãƒ¢ãƒ¼ãƒ‰ãƒãƒ¼è¡¨ç¤ºã‚’æœ‰åŠ¹ã«
                    "modeBarButtonsToRemove": [
                        "zoom2d", "pan2d", "select2d", "lasso2d", "zoomIn2d", "zoomOut2d",
                        "autoScale2d", "resetScale2d", "hoverClosestCartesian", "hoverCompareCartesian",
                        "toggleSpikelines", "toImage"
                    ],
                    "modeBarButtonsToAdd": ["toggleFullscreen"]  # â† å…¨ç”»é¢ãƒœã‚¿ãƒ³ã®ã¿æœ‰åŠ¹
                }
        )
        tmpfile.seek(0)
        html_data = tmpfile.read()

    b64 = base64.b64encode(html_data).decode("utf-8")
    href = f'''
        <a href="data:text/html;base64,{b64}" download="field_map.html">
            <button style="
                background-color: #007BFF;
                color: white;
                padding: 10px 20px;
                border: none;
                border-radius: 6px;
                font-size: 16px;
                cursor: pointer;
            ">ğŸ“¥ HTMLã§åœ°å›³ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</button>
        </a>
    '''
    st.markdown(f"<div style='text-align:center'>{href}</div>", unsafe_allow_html=True)

def to_jst_ymd(date_str):
    if not date_str:
        return ""
    try:
        dt_utc = datetime.fromisoformat(date_str.replace("Z", "+00:00"))
        dt_jst = dt_utc.astimezone(timezone(timedelta(hours=9)))
        return dt_jst.strftime("%Y-%m-%d")  # â† æ—¥ä»˜ã®ã¿ï¼ˆæ™‚åˆ»ãªã—ï¼‰
    except Exception:
        return date_str  # å¤‰æ›å¤±æ•—æ™‚ã¯ãã®ã¾ã¾

def create_kml_from_bbch_df(bbch_df):
    kml = Element('kml')
    document = SubElement(kml, 'Document', {'id': 'featureCollection'})

    # åœƒå ´åãƒ»ä½œä»˜UUIDã§ã¾ã¨ã‚ã‚‹
    grouped = bbch_df.groupby(["åœƒå ´å", "ä½œç‰©", "ä½œä»˜UUID"])

    for (field_name, crop_name, cs_uuid), group in grouped:
        first = group.iloc[0]
        placemark = SubElement(document, 'Placemark', {'id': cs_uuid})

        # <name>
        name = SubElement(placemark, 'name')
        name.text = f"{field_name} - {crop_name}"

        # Geometry
        multi_geometry = SubElement(placemark, 'MultiGeometry')
        polygon = SubElement(multi_geometry, 'Polygon')
        outer = SubElement(polygon, 'outerBoundaryIs')
        ring = SubElement(outer, 'LinearRing')
        coords = SubElement(ring, 'coordinates')

        # ãƒãƒªã‚´ãƒ³åº§æ¨™
        try:
            poly_json = json.loads(first.get("ãƒãƒªã‚´ãƒ³æƒ…å ±", ""))
            coordinates = []
            if poly_json["type"] == "Polygon":
                rings = poly_json["coordinates"]
            elif poly_json["type"] == "MultiPolygon":
                rings = poly_json["coordinates"][0]
            else:
                continue

            for lon, lat in rings[0]:
                coordinates.append(f"{lon},{lat}")
            coords.text = " ".join(coordinates)
        except Exception:
            continue

        # <ExtendedData>
        ext_data = SubElement(placemark, "ExtendedData")

        # é€šå¸¸ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å‡ºåŠ›
        info_keys = [
            "å“ç¨®", "ä½œä»˜æ–¹æ³•", "ä½œä»˜æ™‚ã®BBCH", "ä½œä»˜æ—¥",
            "é¢ç© (a)", "éƒ½é“åºœçœŒ", "å¸‚åŒºç”ºæ‘", "ä¸­å¿ƒåº§æ¨™"
        ]
        for key in info_keys:
            val = first.get(key)
            if pd.notna(val):
                data = SubElement(ext_data, "Data", {"name": key})
                value = SubElement(data, "value")
                value.text = str(val)

        # â–¼ BBCHã‚¹ãƒ†ãƒ¼ã‚¸ã‚’å€‹åˆ¥ã«æ›¸ãå‡ºã™
        for _, row in group.iterrows():
            code = row.get("BBCHã‚³ãƒ¼ãƒ‰")
            name = row.get("BBCHåç§°")
            start = row.get("BBCHé–‹å§‹æ—¥")

            if pd.notna(code) and pd.notna(start):
                # ä¾‹: <Data name="BBCH25"><value>2025-05-19</value></Data>
                data_date = SubElement(ext_data, "Data", {"name": f"BBCH{code}"})
                value_date = SubElement(data_date, "value")
                value_date.text = str(start)

                # ä¾‹: <Data name="BBCH25_èª¬æ˜"><value>åˆ†ã’ã¤æœŸï¼ˆä¸»èŒã¨åˆ†ã’ã¤5æœ¬ï¼‰</value></Data>
                if pd.notna(name):
                    data_desc = SubElement(ext_data, "Data", {"name": f"BBCH{code}_èª¬æ˜"})
                    value_desc = SubElement(data_desc, "value")
                    value_desc.text = str(name)
    # XMLæ•´å½¢
    rough_string = tostring(kml, 'utf-8')
    reparsed = xml.dom.minidom.parseString(rough_string)
    return reparsed.toprettyxml(indent="  ")


# --- å®šæ•°å®šç¾© ---
BASE_LOGIN_URL = "https://accounts.eu1.gigya.com/accounts.login"
TOKEN_API_URL = "https://fm-api.xarvio.com/api/users/tokens"
GRAPHQL_END_POINT = "https://fm-api.xarvio.com/api/graphql/data"
API_KEY = "3_W-AXsoj7TvX-9gi7S-IGxXfLWVkEbnGSl57M7t49GN538umaKs2EID8hyipAux2y"

# --- ISOã‚³ãƒ¼ãƒ‰ã‹ã‚‰éƒ½é“åºœçœŒåã¸ã®å¤‰æ›è¾æ›¸ ---
ISO_TO_PREF_NAME = {
    "JP-01": "åŒ—æµ·é“", "JP-02": "é’æ£®çœŒ", "JP-03": "å²©æ‰‹çœŒ", "JP-04": "å®®åŸçœŒ",
    "JP-05": "ç§‹ç”°çœŒ", "JP-06": "å±±å½¢çœŒ", "JP-07": "ç¦å³¶çœŒ", "JP-08": "èŒ¨åŸçœŒ",
    "JP-09": "æ ƒæœ¨çœŒ", "JP-10": "ç¾¤é¦¬çœŒ", "JP-11": "åŸ¼ç‰çœŒ", "JP-12": "åƒè‘‰çœŒ",
    "JP-13": "æ±äº¬éƒ½", "JP-14": "ç¥å¥ˆå·çœŒ", "JP-15": "æ–°æ½ŸçœŒ", "JP-16": "å¯Œå±±çœŒ",
    "JP-17": "çŸ³å·çœŒ", "JP-18": "ç¦äº•çœŒ", "JP-19": "å±±æ¢¨çœŒ", "JP-20": "é•·é‡çœŒ",
    "JP-21": "å²é˜œçœŒ", "JP-22": "é™å²¡çœŒ", "JP-23": "æ„›çŸ¥çœŒ", "JP-24": "ä¸‰é‡çœŒ",
    "JP-25": "æ»‹è³€çœŒ", "JP-26": "äº¬éƒ½åºœ", "JP-27": "å¤§é˜ªåºœ", "JP-28": "å…µåº«çœŒ",
    "JP-29": "å¥ˆè‰¯çœŒ", "JP-30": "å’Œæ­Œå±±çœŒ", "JP-31": "é³¥å–çœŒ", "JP-32": "å³¶æ ¹çœŒ",
    "JP-33": "å²¡å±±çœŒ", "JP-34": "åºƒå³¶çœŒ", "JP-35": "å±±å£çœŒ", "JP-36": "å¾³å³¶çœŒ",
    "JP-37": "é¦™å·çœŒ", "JP-38": "æ„›åª›çœŒ", "JP-39": "é«˜çŸ¥çœŒ", "JP-40": "ç¦å²¡çœŒ",
    "JP-41": "ä½è³€çœŒ", "JP-42": "é•·å´çœŒ", "JP-43": "ç†Šæœ¬çœŒ", "JP-44": "å¤§åˆ†çœŒ",
    "JP-45": "å®®å´çœŒ", "JP-46": "é¹¿å…å³¶çœŒ", "JP-47": "æ²–ç¸„çœŒ"
}

def login_to_xarvio(email, password):
    try:
        login_url = f"{BASE_LOGIN_URL}?include=emails,profile,data,sessionInfo&loginID={urllib.parse.quote(email)}&password={urllib.parse.quote(password)}&apiKey={API_KEY}"
        login_res = requests.get(login_url)
        login_res.raise_for_status()
        login_data = login_res.json()

        login_token = login_data["sessionInfo"]["cookieValue"]
        gigya_uuid = login_data["UID"]
        gigya_uuid_signature = login_data["UIDSignature"]
        gigya_signature_timestamp = login_data["signatureTimestamp"]

        token_res = requests.post(TOKEN_API_URL, json={
            "gigyaUuid": gigya_uuid,
            "gigyaUuidSignature": gigya_uuid_signature,
            "gigyaSignatureTimestamp": gigya_signature_timestamp
        }, headers={"Cookie": f"LOGIN_TOKEN={login_token}"})
        token_res.raise_for_status()
        api_token = token_res.json()["token"]
        return login_token, api_token
    except Exception as e:
        st.error(f"ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

def get_farms(api_token, login_token):
    st.session_state["graphql_api_call_count"] += 1
    farms_query = {
        "operationName": "FarmsOverview",
        "variables": {},
        "query": """
            query FarmsOverview {
                farms: farmsV2(uuids: []) {
                    uuid
                    name
                }
            }
        """
    }
    headers = {
        "Content-Type": "application/json",
        "Cookie": f"LOGIN_TOKEN={login_token}; DF_TOKEN={api_token}"
    }
    farms_res = requests.post(GRAPHQL_END_POINT, json=farms_query, headers=headers)
    farms_res.raise_for_status()
    return farms_res.json()["data"]["farms"]


def initialize_session_state():
    keys_defaults = {
        "is_logged_in": False,
        "login_token": None,
        "api_token": None,
        "farms_data": None,
        "show_map": False,
        "selected_stage": None,
        "show_labels": True,
        "graphql_api_call_count": 0,
        "reverse_geocode_api_call_count": 0,
        "reverse_geocode_cache_hits": 0,
        "reverse_geocode_cache_misses": 0,
    }
    for key in ["is_logged_in", "login_token", "api_token", "farms_data"]:
        if key not in st.session_state:
            st.session_state[key] = None if key != "is_logged_in" else False

    if "show_map" not in st.session_state:
        st.session_state["show_map"] = False

    if "selected_stage" not in st.session_state:
        st.session_state["selected_stage"] = None

    if "show_labels" not in st.session_state:
        st.session_state["show_labels"] = True

    # ğŸ‘‡ ã“ã“ã‚’è¿½åŠ 
    if "reverse_geocode_cache_hits" not in st.session_state:
        st.session_state["reverse_geocode_cache_hits"] = 0
    if "reverse_geocode_cache_misses" not in st.session_state:
        st.session_state["reverse_geocode_cache_misses"] = 0
    if "reverse_geocode_api_call_count" not in st.session_state:
        st.session_state["reverse_geocode_api_call_count"] = 0
    if "graphql_api_call_count" not in st.session_state:
        st.session_state["graphql_api_call_count"] = 0


def build_field_dataframe(fields, geolocator):
    field_data = []
    for field in fields:
        field_uuid = field.get("uuid")
        field_name = field.get("name")
        area = round(field.get("area", 0) * 0.01, 2)
        boundary = field.get("boundary", {})
        crop_seasons = field.get("cropSeasonsV2", [])

        prefecture = city = ""
        centroid_lat = centroid_lon = None
        try:
            polygon = shape(boundary)
            if isinstance(polygon, (Polygon, MultiPolygon)):
                centroid = polygon.centroid
                centroid_lat, centroid_lon = round(centroid.y, 6), round(centroid.x, 6)

                if st.session_state.get("use_reverse_geocode", True):
                    address = reverse_geocode(centroid_lat, centroid_lon)
                    iso = address.get("ISO3166-2-lvl4") or address.get("ISO3166-2-lvl3")
                    prefecture = ISO_TO_PREF_NAME.get(iso, "")
                    city = address.get("city", address.get("town", address.get("village", "")))

        except:
            pass

        for cs in crop_seasons or [{}]:
            crop = cs.get("crop", {}).get("name", "æœªç™»éŒ²")
            cs_uuid = cs.get("uuid")
            start_date = to_jst_ymd(cs.get("startDate"))
            variety = cs.get("variety", {}).get("name", "æœªç™»éŒ²")
            cropEstablishmentMethodCode = cs.get("cropEstablishmentMethodCode")
            cropEstablishmentGrowthStageIndex = cs.get("cropEstablishmentGrowthStageIndex")

            field_data.append({
                "Field UUID": field_uuid,
                "è¾²å ´å": field.get("farmName", "ä¸æ˜ãªè¾²å ´"),
                "åœƒå ´å": field_name,
                "ä½œç‰©": crop,
                "å“ç¨®": variety,
                "ä½œä»˜æ–¹æ³•": cropEstablishmentMethodCode,
                "ä½œä»˜æ™‚ã®BBCH": cropEstablishmentGrowthStageIndex,
                "cropseason_uuid": cs_uuid,
                "ä½œä»˜æ—¥": start_date,
                "é¢ç© (a)": area,
                "éƒ½é“åºœçœŒ": prefecture,
                "å¸‚åŒºç”ºæ‘": city,
                "ä¸­å¿ƒåº§æ¨™": f"{centroid_lon}, {centroid_lat}" if centroid_lat and centroid_lon else "",
                "ãƒãƒªã‚´ãƒ³æƒ…å ±": json.dumps(boundary, ensure_ascii=False)
            })
    return field_data

def fetch_fields_for_multiple_farms(farm_uuids, login_token, api_token):
    st.session_state["graphql_api_call_count"] += 1

    all_fields = []
    for farm_uuid in farm_uuids:
        query = {
            "operationName": "CombinedFieldData",
            "variables": {
                "farmUuids": [farm_uuid],
                "languageCode": "ja",
                "cropSeasonLifeCycleStates": ["ACTIVE", "PLANNED"],
                "withBoundarySvg": True
            },
            "query": """
                query CombinedFieldData(
                  $farmUuids: [UUID!]!, 
                  $languageCode: String!, 
                  $cropSeasonLifeCycleStates: [LifecycleState]!, 
                  $withBoundarySvg: Boolean!
                ) {
                  farms: farmsV2(uuids: $farmUuids) {
                    uuid
                    name
                  }
                  fieldsV2(farmUuids: $farmUuids) {
                    uuid
                    name
                    area
                    boundary
                    boundarySvg @include(if: $withBoundarySvg)
                    cropSeasonsV2(lifecycleState: $cropSeasonLifeCycleStates) {
                      uuid
                      startDate
                      crop(languageCode: $languageCode) {
                        name
                      }
                      variety(languageCode: $languageCode) {
                        name
                      }
                      cropEstablishmentGrowthStageIndex
                      cropEstablishmentMethodCode
                      countryCropGrowthStagePredictions {
                        index
                        startDate
                        endDate
                        scale
                        gsOrder
                        cropGrowthStageV2(languageCode: $languageCode) {
                          uuid
                          name
                          code
                        }
                      }
                    }
                  }
                }
            """
        }

        headers = {
            "Content-Type": "application/json",
            "Cookie": f"LOGIN_TOKEN={login_token}; DF_TOKEN={api_token}"
        }

        response = requests.post(GRAPHQL_END_POINT, json=query, headers=headers)
        response.raise_for_status()
        data = response.json()["data"]

        farm_name = data["farms"][0]["name"] if data["farms"] else "ä¸æ˜ãªè¾²å ´"
        fields = data["fieldsV2"]

        # å„åœƒå ´ã«è¾²å ´åã‚’ä»˜ä¸
        for field in fields:
            field["farmName"] = farm_name

        all_fields.extend(fields)

    return all_fields


def extract_bbch_data(fields, selected_field_uuids, geolocator):
    bbch_data = []
    for field in fields:
        if field.get("uuid") not in selected_field_uuids:
            continue

        farm_name = field.get("farmName", "ä¸æ˜ãªè¾²å ´")
        field_name = field.get("name", "ä¸æ˜ãªåœƒå ´å")
        area = round(field.get("area", 0) * 0.01, 2)
        boundary = field.get("boundary", {})
        crop_seasons = field.get("cropSeasonsV2") or []

        prefecture = city = ""
        centroid_lat = centroid_lon = None
        try:
            polygon = shape(boundary)
            if isinstance(polygon, (Polygon, MultiPolygon)):
                centroid = polygon.centroid
                centroid_lat, centroid_lon = round(centroid.y, 6), round(centroid.x, 6)

                if use_reverse_geocode:
                    address = reverse_geocode(centroid_lat, centroid_lon)
                    iso = address.get("ISO3166-2-lvl4") or address.get("ISO3166-2-lvl3")
                    prefecture = ISO_TO_PREF_NAME.get(iso, "")
                    city = address.get("city", address.get("town", address.get("village", "")))
        except:
            pass

        for cs in crop_seasons:
            crop_name = cs.get("crop", {}).get("name", "ä¸æ˜ãªä½œç‰©")
            variety = cs.get("variety", {}).get("name", "æœªç™»éŒ²")
            cs_uuid = cs.get("uuid", "UUIDä¸æ˜")
            cropEstablishmentMethodCode = cs.get("cropEstablishmentMethodCode")
            cropEstablishmentGrowthStageIndex = cs.get("cropEstablishmentGrowthStageIndex")
            start_date = to_jst_ymd(cs.get("startDate"))

            predictions = cs.get("countryCropGrowthStagePredictions")
            if not predictions:
                continue

            for pred in predictions:
                gs = pred.get("cropGrowthStageV2")
                if not gs:
                    continue
                coords = []
                try:
                    poly_json = boundary
                    if poly_json["type"] == "Polygon":
                        coords = poly_json["coordinates"][0]
                    elif poly_json["type"] == "MultiPolygon":
                        coords = poly_json["coordinates"][0][0]
                except Exception:
                    pass
                
                bbch_data.append({
                    "è¾²å ´å": farm_name,
                    "åœƒå ´å": field_name,
                    "ä½œç‰©": crop_name,
                    "ä½œä»˜UUID": cs_uuid,
                    "BBCHã‚³ãƒ¼ãƒ‰": gs.get("code", "ä¸æ˜"),
                    "BBCHåç§°": gs.get("name", "ä¸æ˜"),
                    "å“ç¨®": variety,
                    "ä½œä»˜æ–¹æ³•": cropEstablishmentMethodCode,
                    "ä½œä»˜æ™‚ã®BBCH": cropEstablishmentGrowthStageIndex,
                    "ä½œä»˜æ—¥": start_date,
                    "é¢ç© (a)": area,
                    "éƒ½é“åºœçœŒ": prefecture,
                    "å¸‚åŒºç”ºæ‘": city,
                    "ä¸­å¿ƒåº§æ¨™": f"{centroid_lon}, {centroid_lat}" if centroid_lat and centroid_lon else "",
                    "ãƒãƒªã‚´ãƒ³æƒ…å ±": json.dumps(boundary, ensure_ascii=False),
                    "BBCHé–‹å§‹æ—¥": to_jst_ymd(pred.get("startDate", "ä¸æ˜")),
                    "coords": coords,
                    "date": to_jst_ymd(pred.get("startDate", "")),
                    "name": field_name,
                    "variety": variety
                })
    return bbch_data

# ----------------------------------
# ã‚¢ãƒ—ãƒªå®Ÿè¡Œéƒ¨åˆ†
# ----------------------------------

tab1, tab2, tab3, tab4 = st.tabs(["ğŸŒ¾ xarvio","ğŸ“Š ã‚°ãƒ©ãƒ•", "ğŸ“‹ BBCHä¸€è¦§ï¼ˆPIVOTï¼‰", "ğŸ—º åœ°å›³"])

# --- Streamlit ãƒšãƒ¼ã‚¸è¨­å®š ---
with tab1:
    
    initialize_session_state()
    st.title("ğŸŒ¾ xarvio åœƒå ´ãƒãƒƒãƒ—ãƒ“ãƒ¥ãƒ¼ã‚¢")

    # --- ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ  ---
    if not st.session_state.is_logged_in:
        with st.form("login_form"):
            email = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹")
            password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
            submitted = st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³")

        if submitted:
            if not email or not password:
                st.warning("âš ï¸ ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ä¸¡æ–¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                login_token, api_token = login_to_xarvio(email, password)
                if login_token and api_token:
                    farms = get_farms(api_token, login_token)
                    st.session_state.login_token = login_token
                    st.session_state.api_token = api_token
                    st.session_state.farms_data = farms
                    st.session_state.is_logged_in = True
                    st.rerun()
                else:
                    st.warning("âš ï¸ ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‹ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")

    # --- ãƒ­ã‚°ã‚¤ãƒ³å¾Œå‡¦ç† ---
    if st.session_state.is_logged_in:
        st.success("ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿")

        farms = st.session_state.farms_data
        farm_name_to_uuid = {f["name"]: f["uuid"] for f in farms}

        selected_farm_names = st.multiselect("ğŸšœ è¤‡æ•°ã®è¾²å ´ã‚’é¸æŠ", list(farm_name_to_uuid.keys()))
        selected_farm_uuids = [farm_name_to_uuid[name] for name in selected_farm_names]

        if "geolocator" not in st.session_state:
            st.session_state.geolocator = Nominatim(user_agent="xarvio-app")

        # åœ°åŸŸæƒ…å ±ã‚’å–å¾—ã™ã‚‹ã‹ã©ã†ã‹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        use_reverse_geocode = st.toggle("ğŸ“ åœ°åŸŸæƒ…å ±ï¼ˆéƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘ï¼‰ã‚’å–å¾—ã™ã‚‹ï¼ˆå‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚ï¼‰", value=False)
        st.session_state.use_reverse_geocode = use_reverse_geocode

        if st.button("ğŸ“¥ åœƒå ´æƒ…å ±ã‚’å–å¾—"):
            if not selected_farm_uuids:
                st.warning("âš ï¸ å–å¾—ã™ã‚‹è¾²å ´ã‚’1ã¤ä»¥ä¸Šé¸ã‚“ã§ãã ã•ã„ã€‚")
                st.stop()
            total_start = time.time()
            status = st.empty()
            status.info("ğŸ”„ åœƒå ´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            # Step 1: APIå‘¼ã³å‡ºã—
            t1 = time.time()
            geolocator = Nominatim(user_agent="xarvio-app")
            fields = fetch_fields_for_multiple_farms(
                selected_farm_uuids,
                st.session_state.login_token,
                st.session_state.api_token
            )
            t2 = time.time()
            st.markdown(f"âœ… **APIå–å¾—æ™‚é–“**: `{t2 - t1:.2f}ç§’`ã€€ï½œã€€**åœƒå ´æ•°**: `{len(fields)}`ä»¶")
            st.success(f"âœ… APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—å®Œäº†ï¼ˆ{t2 - t1:.2f}ç§’ï¼‰")
            # Step 2: ãƒ‡ãƒ¼ã‚¿æ•´å½¢
            t3 = time.time()
            field_data = build_field_dataframe(fields, geolocator)
            t4 = time.time()
            st.success(f"âœ… åœƒå ´ãƒ‡ãƒ¼ã‚¿æ•´å½¢å®Œäº†ï¼ˆ{t4 - t3:.2f}ç§’ï¼‰")
            # Step 3: DataFrameç”Ÿæˆ
            t5 = time.time()
            df = pd.DataFrame(field_data)
            st.session_state.fields = fields
            st.session_state.field_data = field_data
            st.session_state.df = df
            t6 = time.time()
            st.success(f"âœ… DataFrameæ§‹ç¯‰å®Œäº†ï¼ˆ{t6 - t5:.2f}ç§’ï¼‰")
            total_end = time.time()
            st.info(f"â±ï¸ å…¨å‡¦ç†æ™‚é–“: {total_end - total_start:.2f} ç§’")
            status.empty()

        if "df" in st.session_state:
            df = st.session_state.df

            st.subheader("ğŸ“‹ åœƒå ´ä¸€è¦§ï¼ˆBBCHé¸æŠå¯èƒ½ï¼‰")
            gb = GridOptionsBuilder.from_dataframe(df)
            gb.configure_selection(selection_mode="multiple", use_checkbox=True)
            gb.configure_column("Field UUID", headerCheckboxSelection=True, checkboxSelection=True)
            grid_options = gb.build()

            with st.form("select_fields"):
#                grid_response = AgGrid(df, gridOptions=grid_options, update_mode=GridUpdateMode.SELECTION_CHANGED)
                grid_response = AgGrid(df, gridOptions=grid_options, update_mode=GridUpdateMode.MODEL_CHANGED)

                submit = st.form_submit_button("ğŸ¯ BBCHå–å¾—")

            if submit:
                selected_rows = grid_response.selected_rows
                if selected_rows is None or selected_rows.empty:
                    st.warning("âš  åœƒå ´ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
                    st.stop()
                else:
                    if isinstance(selected_rows, pd.DataFrame):
                        selected_rows = selected_rows.to_dict(orient="records")

                    if not isinstance(selected_rows[0], dict):
                        st.error("âš ï¸ é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒæƒ³å®šã¨ç•°ãªã‚Šã¾ã™ã€‚")
                        st.stop()

                    selected_field_uuids = [r["Field UUID"] for r in selected_rows]
                    status = st.empty()
                    status.info("â³ BBCHãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­...")
                    

                    total_start = time.time()

                    t1 = time.time()

                    geolocator = Nominatim(user_agent="xarvio-app")
                    bbch_data = extract_bbch_data(st.session_state.fields, selected_field_uuids, geolocator)
                    t2 = time.time()
                    st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚ã‚¿ãƒ–ã‚’åˆ‡ã‚Šæ›¿ãˆã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå®Œäº†ï¼ˆ{t2 - t1:.2f} ç§’ï¼‰")

                    t3 = time.time()
                    bbch_df = pd.DataFrame(bbch_data)

                    if not bbch_df.empty:
                        bbch_df["BBCHã‚¹ãƒ†ãƒ¼ã‚¸"] = bbch_df["BBCHã‚³ãƒ¼ãƒ‰"].astype(str) + " (" + bbch_df["BBCHåç§°"] + ")"
                        st.session_state.bbch_df = bbch_df  # ğŸ¯ ä¿å­˜
                    t4 = time.time()
                    st.success(f"âœ… DataFrameæ•´å½¢å®Œäº†ï¼ˆ{t4 - t3:.2f} ç§’ï¼‰")
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨çŠ¶æ³ã®è¡¨ç¤º
                    #st.markdown(f"ğŸ§  **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨**: `reverse_geocode` â†’ {'ä½¿ç”¨æ¸ˆã¿ï¼ˆ@st.cache_dataï¼‰' if use_reverse_geocode else 'æœªä½¿ç”¨ï¼ˆãƒã‚§ãƒƒã‚¯ã‚ªãƒ•ï¼‰'}`")
                    total_end = time.time()
                    st.info(f"â±ï¸ BBCHå–å¾— å…¨å‡¦ç†æ™‚é–“: **{total_end - total_start:.2f} ç§’**")
                    status.empty()


                    if bbch_df.empty:
                        selected_field_names = [r["åœƒå ´å"] for r in selected_rows if "åœƒå ´å" in r]
                        st.warning("âš ï¸ é¸æŠã•ã‚ŒãŸåœƒå ´ã¯BBCHã®æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬æ©Ÿèƒ½ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                        st.markdown("#### ğŸ“‹ BBCHãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„åœƒå ´")
                        st.write(selected_field_names)

            if "bbch_df" in st.session_state:
                bbch_df = st.session_state.bbch_df

                pivot_index_cols = [
                    "è¾²å ´å", "åœƒå ´å", "ä½œç‰©", "ä½œä»˜UUID", "å“ç¨®", "ä½œä»˜æ–¹æ³•",
                    "ä½œä»˜æ™‚ã®BBCH", "ä½œä»˜æ—¥", "é¢ç© (a)",
                    "éƒ½é“åºœçœŒ", "å¸‚åŒºç”ºæ‘", "ä¸­å¿ƒåº§æ¨™" #, "ãƒãƒªã‚´ãƒ³æƒ…å ±"
                ]

                pivot_df = bbch_df.pivot_table(
                    index=pivot_index_cols,
                    columns="BBCHã‚¹ãƒ†ãƒ¼ã‚¸",
                    values="BBCHé–‹å§‹æ—¥",
                    aggfunc="first"
                ).reset_index()
                pivot_df.columns.name = None
                st.session_state.pivot_df = pivot_df
            with tab2:
                st.subheader("ğŸ“Š é¸æŠåœƒå ´ã®BBCHã‚¹ãƒ†ãƒ¼ã‚¸ä¸€è¦§")
                if "pivot_df" in st.session_state:
                    pivot_df = st.session_state.pivot_df
                    gb = GridOptionsBuilder.from_dataframe(pivot_df)
                    gb.configure_default_column(resizable=True)
                    gb.configure_grid_options(domLayout='normal', enableCharts=True, enableRangeSelection=True)
                    grid_options = gb.build()
                    plot_bbch_stacked_bar(bbch_df)
                else:
                    st.warning("âš  PIVOTãƒ‡ãƒ¼ã‚¿ãŒã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«åœƒå ´ã‚’é¸æŠã—ã¦BBCHã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚")
                
            # ç©ç«‹æ£’ã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
            #plot_bbch_stacked_bar(bbch_df)
            with tab3:
                st.subheader("ğŸ“‹ PIVOTãƒ‡ãƒ¼ã‚¿")
                
                if "pivot_df" in st.session_state:
                    pivot_df = st.session_state.pivot_df
                    AgGrid(
                        pivot_df,
                        gridOptions=grid_options,
                        update_mode=GridUpdateMode.NO_UPDATE,
                        fit_columns_on_grid_load=False,  # æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ç”¨ã«ã‚«ãƒ©ãƒ å¹…ã‚’è‡ªå‹•ã§è©°ã‚ãªã„
                        allow_unsafe_jscode=True,
                        height=500
                    )

                    csv = pivot_df.to_csv(index=False).encode("utf-8-sig")
                    st.download_button("ğŸ“¥ BBCHã‚¹ãƒ†ãƒ¼ã‚¸ä¸€è¦§ï¼ˆCSVï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="BBCHã‚¹ãƒ†ãƒ¼ã‚¸ä¸€è¦§.csv", mime="text/csv")
                else:
                    st.warning("âš  PIVOTãƒ‡ãƒ¼ã‚¿ãŒã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«åœƒå ´ã‚’é¸æŠã—ã¦BBCHã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚")

            with tab4:                    
                # åœ°å›³ã®ç”Ÿæˆã¨è¡¨ç¤º
                if "bbch_df" in st.session_state:
                    bbch_df = st.session_state.bbch_df
                    bbch_records = bbch_df.to_dict(orient="records")
                    selected_map_style, selected_bbch, title_prefix, selected_label = get_user_inputs(bbch_records)


                    # ã‚¿ã‚¤ãƒˆãƒ«ã®ç”Ÿæˆã¨è¡¨ç¤º
                    map_title = generate_map_title(title_prefix, selected_bbch)

                    st.markdown(f"### ğŸ“Œ ç¾åœ¨ã®è¡¨ç¤º: {map_title}")

                    # åœƒå ´åã§ã‚½ãƒ¼ãƒˆã—ã¦é¸æŠè‚¢ã‚’ä½œã‚‹
                    field_options = {
                        f'{row["åœƒå ´å"]}ï¼ˆ{row.get("è¾²å ´å", "ä¸æ˜ãªè¾²å ´")}ï¼‰': row["ä¸­å¿ƒåº§æ¨™"]
                        for row in sorted(
                            bbch_df.dropna(subset=["ä¸­å¿ƒåº§æ¨™"]).to_dict(orient="records"),
                            key=lambda x: x["åœƒå ´å"]
                        )
                    }


                    # UIã®é¸æŠãƒœãƒƒã‚¯ã‚¹
                    selected_jump_field = st.selectbox("ğŸ“ åœ°å›³ã‚’ã‚ºãƒ¼ãƒ è¡¨ç¤ºã—ãŸã„åœƒå ´ã‚’é¸ã‚“ã§ãã ã•ã„", options=list(field_options.keys()))

                    # é¸æŠã•ã‚ŒãŸåœƒå ´ã®ä¸­å¿ƒåº§æ¨™ã‚’å–å¾—
                    jump_lat, jump_lon = extract_lat_lon(field_options[selected_jump_field])


                    # åœ°å›³ç”Ÿæˆãƒ»è¡¨ç¤º
                    fig = create_field_map(
                        field_data=bbch_records,
                        selected_bbch=selected_bbch,
                        map_style=selected_map_style,
                        map_title=map_title,
                        label_key=selected_label,
                        center_override={"lat": jump_lat, "lon": jump_lon},
                        zoom_override=14  # é©åº¦ã«ã‚ºãƒ¼ãƒ ã‚¤ãƒ³
                    )
                    st.plotly_chart(fig, use_container_width=True, 
                            #    config={"scrollZoom": True, "displayModeBar": False})
                                config={
                                "scrollZoom": True,
                                "displayModeBar": True,  # ãƒ¢ãƒ¼ãƒ‰ãƒãƒ¼è¡¨ç¤ºã‚’æœ‰åŠ¹ã«
                                "modeBarButtonsToRemove": [
                                    "zoom2d", "pan2d", "select2d", "lasso2d", "zoomIn2d", "zoomOut2d",
                                    "autoScale2d", "resetScale2d", "hoverClosestCartesian", "hoverCompareCartesian",
                                    "toggleSpikelines"
                                ],
                                "modeBarButtonsToAdd": ["toggleFullscreen", "toImage"]  # â† å…¨ç”»é¢ãƒœã‚¿ãƒ³ã®ã¿æœ‰åŠ¹
                                })
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    download_map_html(fig)


                # === ğŸ—‚ BBCHã”ã¨ã«KMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ===
                if "bbch_df" in st.session_state:
                    bbch_df = st.session_state.bbch_df

                    st.markdown("### ğŸ“¦ BBCHã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ã«KMLã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                    selected_bbch_codes = st.multiselect(
                        "ğŸ“Œ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸã„BBCHã‚³ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„",
                        sorted(bbch_df["BBCHã‚³ãƒ¼ãƒ‰"].unique()),
                        default=[],
                    )

                    for code in selected_bbch_codes:
                        filtered_df = bbch_df[bbch_df["BBCHã‚³ãƒ¼ãƒ‰"] == code]
                        if not filtered_df.empty:
                            kml_content = create_kml_from_bbch_df(filtered_df).encode("utf-8")
                            bbch_name = filtered_df.iloc[0]["BBCHåç§°"]
                            file_name = f"bbch_{code}_{bbch_name}.kml".replace(" ", "_").replace("ï¼ˆ", "_").replace("ï¼‰", "_")

                            st.download_button(
                                label=f"ğŸ“¥ KMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ - BBCH{code}ï¼ˆ{bbch_name}ï¼‰",
                                data=kml_content,
                                file_name=file_name,
                                mime="application/vnd.google-earth.kml+xml",
                                key=f"kml_download_{code}"
                            )
                with st.expander("ğŸš— BBCHåœƒå ´ã®ãŠã™ã™ã‚å·¡å›ãƒ«ãƒ¼ãƒˆã‚’è¡¨ç¤º", expanded=False):
                    if "bbch_df" in st.session_state:
                        bbch_df = st.session_state.bbch_df

                        # â‘  BBCHã‚³ãƒ¼ãƒ‰ã‚’é¸æŠ
                        bbch_codes = sorted(
                            bbch_df["BBCHã‚³ãƒ¼ãƒ‰"].dropna().unique(),
                            key=lambda x: int(x) if str(x).isdigit() else x
                        )
                        selected_bbch_code = st.selectbox("â‘  å¯¾è±¡ã®BBCHã‚³ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„", bbch_codes)

                        # â‘¡ é¸æŠã•ã‚ŒãŸBBCHã‚³ãƒ¼ãƒ‰ã«å¯¾å¿œã™ã‚‹é–‹å§‹æ—¥ã‚’ã€Œè¤‡æ•°é¸æŠã€
                        bbch_dates = sorted(
                            bbch_df[bbch_df["BBCHã‚³ãƒ¼ãƒ‰"] == selected_bbch_code]["BBCHé–‹å§‹æ—¥"].dropna().unique(),
                            key=lambda x: pd.to_datetime(x)
                        )
                        selected_dates = st.multiselect("â‘¡ è©²å½“BBCHã‚¹ãƒ†ãƒ¼ã‚¸ã®é–‹å§‹æ—¥ã‚’é¸ã‚“ã§ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰", bbch_dates, default=bbch_dates)

                        # â‘¢ BBCH + é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã«è©²å½“ã™ã‚‹åœƒå ´ã®ã¿æŠ½å‡º
                        filtered_df = bbch_df[
                            (bbch_df["BBCHã‚³ãƒ¼ãƒ‰"] == selected_bbch_code) &
                            (bbch_df["BBCHé–‹å§‹æ—¥"].isin(selected_dates))
                        ].dropna(subset=["ä¸­å¿ƒåº§æ¨™"])

                        field_names = sorted(filtered_df["åœƒå ´å"].dropna().unique())
                        selected_fields = st.multiselect("â‘¢ å·¡å›å¯¾è±¡ã¨ã™ã‚‹åœƒå ´ã‚’é¸ã‚“ã§ãã ã•ã„", options=field_names, default=field_names)

                        # â‘£ Googleãƒãƒƒãƒ—ã®ä¸Šé™ï¼ˆ23ä»¶ï¼‰åˆ¶é™
                        if len(selected_fields) > 23:
                            st.warning("âš ï¸ Googleãƒãƒƒãƒ—ã®ä»•æ§˜ã«ã‚ˆã‚Šã€é¸æŠã§ãã‚‹åœƒå ´ã¯æœ€å¤§23å€‹ã¾ã§ã§ã™ã€‚")
                            selected_fields = selected_fields[:23]

                        # â‘¤ å·¡å›ãƒ«ãƒ¼ãƒˆç”Ÿæˆ
                        if selected_fields:
                            selected_df = filtered_df[filtered_df["åœƒå ´å"].isin(selected_fields)]
                            route_input = []
                            for _, row in selected_df.iterrows():
                                lat, lon = extract_lat_lon(row["ä¸­å¿ƒåº§æ¨™"])
                                if lat and lon:
                                    route_input.append({
                                        "name": row["åœƒå ´å"],
                                        "lat": lat,
                                        "lon": lon
                                    })

                            if len(route_input) >= 2:
                                # Greedyãªãƒ«ãƒ¼ãƒˆä½œæˆ
                                start = route_input[0]
                                route = [start]
                                unvisited = route_input[1:]

                                while unvisited:
                                    last = route[-1]
                                    next_point = min(unvisited, key=lambda p: geodesic((last["lat"], last["lon"]), (p["lat"], p["lon"])).km)
                                    route.append(next_point)
                                    unvisited.remove(next_point)

                                # Googleãƒãƒƒãƒ—ç”¨ã®URLï¼ˆç¾åœ¨åœ°ã‚¹ã‚¿ãƒ¼ãƒˆãƒ»æˆ»ã‚‹ï¼‰
                                gmap_url = generate_google_maps_route(route)

                                st.markdown("### ğŸ§­ å·¡å›ãƒ«ãƒ¼ãƒˆï¼ˆGoogleãƒãƒƒãƒ—ï¼‰")
                                st.markdown(f"[ğŸ“ é“é †ã‚’è¡¨ç¤ºã™ã‚‹]({gmap_url})", unsafe_allow_html=True)

                                st.markdown("#### ğŸ” å·¡å›é †ã®åœƒå ´ä¸€è¦§")
                                for i, pt in enumerate(route, start=1):
                                    st.markdown(f"{i}. **{pt['name']}**ï¼ˆ{pt['lat']:.5f}, {pt['lon']:.5f}ï¼‰")
                            else:
                                st.warning("âš ï¸ 2ã¤ä»¥ä¸Šã®åœƒå ´ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
